{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling as pp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_path = '/home/srgrace/genericContest_data/cat-in-the-dat-ii'\n",
    "\n",
    "train = pd.read_csv(os.path.join(data_path, 'train.csv'))\n",
    "test = pd.read_csv(os.path.join(data_path, 'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>nom_0</th>\n",
       "      <th>nom_1</th>\n",
       "      <th>nom_2</th>\n",
       "      <th>nom_3</th>\n",
       "      <th>...</th>\n",
       "      <th>nom_9</th>\n",
       "      <th>ord_0</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>ord_3</th>\n",
       "      <th>ord_4</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Russia</td>\n",
       "      <td>...</td>\n",
       "      <td>02e7c8990</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>Hot</td>\n",
       "      <td>c</td>\n",
       "      <td>U</td>\n",
       "      <td>Pw</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Red</td>\n",
       "      <td>Star</td>\n",
       "      <td>Axolotl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>f37df64af</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Warm</td>\n",
       "      <td>e</td>\n",
       "      <td>X</td>\n",
       "      <td>pE</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Canada</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>n</td>\n",
       "      <td>P</td>\n",
       "      <td>eN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Circle</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Finland</td>\n",
       "      <td>...</td>\n",
       "      <td>f9d456e57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Novice</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>a</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Triangle</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>...</td>\n",
       "      <td>c5361037c</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Cold</td>\n",
       "      <td>h</td>\n",
       "      <td>C</td>\n",
       "      <td>OZ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  bin_0  bin_1  bin_2 bin_3 bin_4 nom_0      nom_1    nom_2       nom_3  \\\n",
       "0   0    0.0    0.0    0.0     F     N   Red  Trapezoid  Hamster      Russia   \n",
       "1   1    1.0    1.0    0.0     F     Y   Red       Star  Axolotl         NaN   \n",
       "2   2    0.0    1.0    0.0     F     N   Red        NaN  Hamster      Canada   \n",
       "3   3    NaN    0.0    0.0     F     N   Red     Circle  Hamster     Finland   \n",
       "4   4    0.0    NaN    0.0     T     N   Red   Triangle  Hamster  Costa Rica   \n",
       "\n",
       "   ...        nom_9 ord_0        ord_1     ord_2 ord_3 ord_4  ord_5  day  \\\n",
       "0  ...    02e7c8990   3.0  Contributor       Hot     c     U     Pw  6.0   \n",
       "1  ...    f37df64af   3.0  Grandmaster      Warm     e     X     pE  7.0   \n",
       "2  ...          NaN   3.0          NaN  Freezing     n     P     eN  5.0   \n",
       "3  ...    f9d456e57   1.0       Novice  Lava Hot     a     C    NaN  3.0   \n",
       "4  ...    c5361037c   3.0  Grandmaster      Cold     h     C     OZ  5.0   \n",
       "\n",
       "  month target  \n",
       "0   3.0      0  \n",
       "1   7.0      0  \n",
       "2   9.0      0  \n",
       "3   3.0      0  \n",
       "4  12.0      0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>nom_0</th>\n",
       "      <th>nom_1</th>\n",
       "      <th>nom_2</th>\n",
       "      <th>nom_3</th>\n",
       "      <th>...</th>\n",
       "      <th>nom_8</th>\n",
       "      <th>nom_9</th>\n",
       "      <th>ord_0</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>ord_3</th>\n",
       "      <th>ord_4</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>Axolotl</td>\n",
       "      <td>Finland</td>\n",
       "      <td>...</td>\n",
       "      <td>ca9ad1d4b</td>\n",
       "      <td>fced9e114</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Novice</td>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>f</td>\n",
       "      <td>U</td>\n",
       "      <td>oU</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Red</td>\n",
       "      <td>Circle</td>\n",
       "      <td>Lion</td>\n",
       "      <td>Russia</td>\n",
       "      <td>...</td>\n",
       "      <td>060a21580</td>\n",
       "      <td>7ca8775da</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Novice</td>\n",
       "      <td>Cold</td>\n",
       "      <td>n</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Circle</td>\n",
       "      <td>Axolotl</td>\n",
       "      <td>Russia</td>\n",
       "      <td>...</td>\n",
       "      <td>165e81a00</td>\n",
       "      <td>5940334c9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Expert</td>\n",
       "      <td>Warm</td>\n",
       "      <td>i</td>\n",
       "      <td>N</td>\n",
       "      <td>DN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>Axolotl</td>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>...</td>\n",
       "      <td>77d41330d</td>\n",
       "      <td>6fbdeefc8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Expert</td>\n",
       "      <td>Hot</td>\n",
       "      <td>m</td>\n",
       "      <td>B</td>\n",
       "      <td>AG</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Red</td>\n",
       "      <td>Circle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Finland</td>\n",
       "      <td>...</td>\n",
       "      <td>2218d9dfe</td>\n",
       "      <td>2a27c8fde</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>o</td>\n",
       "      <td>J</td>\n",
       "      <td>DT</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  bin_0  bin_1  bin_2 bin_3 bin_4 nom_0    nom_1    nom_2  \\\n",
       "0  600000    0.0    0.0    0.0     F     Y  Blue  Polygon  Axolotl   \n",
       "1  600001    0.0    0.0    0.0     F     Y   Red   Circle     Lion   \n",
       "2  600002    0.0    0.0    0.0     F     Y  Blue   Circle  Axolotl   \n",
       "3  600003    1.0    0.0    0.0     F     N   Red  Polygon  Axolotl   \n",
       "4  600004    0.0    0.0    1.0     F     Y   Red   Circle      NaN   \n",
       "\n",
       "        nom_3  ...       nom_8      nom_9 ord_0        ord_1        ord_2  \\\n",
       "0     Finland  ...   ca9ad1d4b  fced9e114   3.0       Novice  Boiling Hot   \n",
       "1      Russia  ...   060a21580  7ca8775da   1.0       Novice         Cold   \n",
       "2      Russia  ...   165e81a00  5940334c9   1.0       Expert         Warm   \n",
       "3  Costa Rica  ...   77d41330d  6fbdeefc8   1.0       Expert          Hot   \n",
       "4     Finland  ...   2218d9dfe  2a27c8fde   1.0  Contributor     Lava Hot   \n",
       "\n",
       "  ord_3  ord_4 ord_5  day month  \n",
       "0     f      U    oU  3.0   9.0  \n",
       "1     n      N   NaN  2.0   8.0  \n",
       "2     i      N    DN  2.0   6.0  \n",
       "3     m      B    AG  1.0   6.0  \n",
       "4     o      J    DT  3.0   3.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import gc\n",
    "import joblib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics, preprocessing\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['target'] = -1\n",
    "data = pd.concat([train, test]).reset_index(drop=True)\n",
    "\n",
    "features = [x for x in train.columns if x not in ['id', 'target']]\n",
    "\n",
    "for feat in features:\n",
    "    label_enc = preprocessing.LabelEncoder()\n",
    "    data[feat] = label_enc.fit_transform(data[feat].fillna('-1').astype(str).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[data.target != -1].reset_index(drop=True)\n",
    "test = data[data.target == -1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>nom_0</th>\n",
       "      <th>nom_1</th>\n",
       "      <th>nom_2</th>\n",
       "      <th>nom_3</th>\n",
       "      <th>...</th>\n",
       "      <th>nom_9</th>\n",
       "      <th>ord_0</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>ord_3</th>\n",
       "      <th>ord_4</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>599995</th>\n",
       "      <td>599995</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599996</th>\n",
       "      <td>599996</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1403</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>164</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599997</th>\n",
       "      <td>599997</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>572</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>43</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599998</th>\n",
       "      <td>599998</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1712</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599999</th>\n",
       "      <td>599999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1974</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>168</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  bin_0  bin_1  bin_2  bin_3  bin_4  nom_0  nom_1  nom_2  nom_3  \\\n",
       "599995  599995      1      2      1      2      1      3      2      1      5   \n",
       "599996  599996      2      1      1      2      2      1      2      3      3   \n",
       "599997  599997      1      1      1      1      2      3      1      1      6   \n",
       "599998  599998      2      2      1      1      2      0      2      1      0   \n",
       "599999  599999      1      1      1      2      1      1      6      3      6   \n",
       "\n",
       "         ...    nom_9  ord_0  ord_1  ord_2  ord_3  ord_4  ord_5  day  month  \\\n",
       "599995   ...       14      3      5      3      1     18     23    5      0   \n",
       "599996   ...     1403      2      5      1     14     14    164    0      6   \n",
       "599997   ...      572      2      1      3     14      8     43    7      8   \n",
       "599998   ...     1712      1      4      6     13     24     19    1      8   \n",
       "599999   ...     1974      1      1      1      2     15    168    5     11   \n",
       "\n",
       "        target  \n",
       "599995       0  \n",
       "599996       0  \n",
       "599997       0  \n",
       "599998       0  \n",
       "599999       0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "    def fallback_auc(y_true, y_pred):\n",
    "        try:\n",
    "            return metrics.roc_auc_score(y_true, y_pred)\n",
    "        except:\n",
    "            return 0.5\n",
    "    return tf.py_function(fallback_auc, (y_true, y_pred), tf.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(data, feats):\n",
    "    inps = []\n",
    "    outs = []\n",
    "    for feat in feats:\n",
    "        num_unique_vals = int(data[feat].nunique())\n",
    "        embed_dim = int(min(np.ceil(num_unique_vals/2), 50))\n",
    "        \n",
    "        inp = layers.Input(shape=(1, ))\n",
    "        out = layers.Embedding(num_unique_vals + 1, embed_dim, name=feat)(inp)\n",
    "        \n",
    "        out = layers.SpatialDropout1D(0.5)(out)\n",
    "        out = layers.Reshape(target_shape=(embed_dim, ))(out)\n",
    "        \n",
    "        inps.append(inp)\n",
    "        outs.append(out)\n",
    "    \n",
    "    x = layers.Concatenate()(outs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Dense(300, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Dense(300, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    y = layers.Dense(2, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=inps, outputs=y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 587999 samples, validate on 12001 samples\n",
      "Epoch 1/100\n",
      "587999/587999 [==============================] - 43s 74us/sample - loss: 0.4674 - auc: 0.6911 - val_loss: 0.4075 - val_auc: 0.7756\n",
      "Epoch 2/100\n",
      "587999/587999 [==============================] - 22s 37us/sample - loss: 0.4159 - auc: 0.7575 - val_loss: 0.4073 - val_auc: 0.7768\n",
      "Epoch 3/100\n",
      "587999/587999 [==============================] - 19s 33us/sample - loss: 0.4121 - auc: 0.7641 - val_loss: 0.4027 - val_auc: 0.7798\n",
      "Epoch 4/100\n",
      "587999/587999 [==============================] - 19s 32us/sample - loss: 0.4107 - auc: 0.7666 - val_loss: 0.4017 - val_auc: 0.7797\n",
      "Epoch 5/100\n",
      "587999/587999 [==============================] - 19s 32us/sample - loss: 0.4096 - auc: 0.7682 - val_loss: 0.4022 - val_auc: 0.7801\n",
      "Epoch 6/100\n",
      "587999/587999 [==============================] - 20s 35us/sample - loss: 0.4088 - auc: 0.7695 - val_loss: 0.4018 - val_auc: 0.7801\n",
      "Epoch 7/100\n",
      "587999/587999 [==============================] - 22s 38us/sample - loss: 0.4085 - auc: 0.7698 - val_loss: 0.4010 - val_auc: 0.7808\n",
      "Epoch 8/100\n",
      "587999/587999 [==============================] - 21s 35us/sample - loss: 0.4076 - auc: 0.7712 - val_loss: 0.4013 - val_auc: 0.7807\n",
      "Epoch 9/100\n",
      "587999/587999 [==============================] - 21s 35us/sample - loss: 0.4071 - auc: 0.7719 - val_loss: 0.4067 - val_auc: 0.7803\n",
      "Epoch 10/100\n",
      "587999/587999 [==============================] - 21s 35us/sample - loss: 0.4066 - auc: 0.7728 - val_loss: 0.4027 - val_auc: 0.7810\n",
      "Epoch 11/100\n",
      "587999/587999 [==============================] - 21s 35us/sample - loss: 0.4067 - auc: 0.7725 - val_loss: 0.4019 - val_auc: 0.7810\n",
      "Epoch 12/100\n",
      "587776/587999 [============================>.] - ETA: 0s - loss: 0.4061 - auc: 0.7732Restoring model weights from the end of the best epoch.\n",
      "587999/587999 [==============================] - 21s 36us/sample - loss: 0.4061 - auc: 0.7731 - val_loss: 0.4048 - val_auc: 0.7807\n",
      "Epoch 00012: early stopping\n",
      "0.7805419414617846\n",
      "Train on 587999 samples, validate on 12001 samples\n",
      "Epoch 1/100\n",
      "587999/587999 [==============================] - 23s 39us/sample - loss: 0.4666 - auc: 0.6927 - val_loss: 0.4063 - val_auc: 0.7899\n",
      "Epoch 2/100\n",
      "587999/587999 [==============================] - 18s 30us/sample - loss: 0.4163 - auc: 0.7569 - val_loss: 0.3978 - val_auc: 0.7929\n",
      "Epoch 3/100\n",
      "587999/587999 [==============================] - 17s 29us/sample - loss: 0.4123 - auc: 0.7640 - val_loss: 0.3932 - val_auc: 0.7946\n",
      "Epoch 4/100\n",
      "587999/587999 [==============================] - 17s 29us/sample - loss: 0.4110 - auc: 0.7660 - val_loss: 0.3937 - val_auc: 0.7951\n",
      "Epoch 5/100\n",
      "587999/587999 [==============================] - 18s 30us/sample - loss: 0.4100 - auc: 0.7677 - val_loss: 0.3952 - val_auc: 0.7944\n",
      "Epoch 6/100\n",
      "587999/587999 [==============================] - 18s 30us/sample - loss: 0.4095 - auc: 0.7684 - val_loss: 0.3952 - val_auc: 0.7946\n",
      "Epoch 7/100\n",
      "587776/587999 [============================>.] - ETA: 0s - loss: 0.4086 - auc: 0.7696\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "587999/587999 [==============================] - 17s 30us/sample - loss: 0.4086 - auc: 0.7695 - val_loss: 0.3979 - val_auc: 0.7945\n",
      "Epoch 8/100\n",
      "586752/587999 [============================>.] - ETA: 0s - loss: 0.4067 - auc: 0.7720Restoring model weights from the end of the best epoch.\n",
      "587999/587999 [==============================] - 18s 31us/sample - loss: 0.4067 - auc: 0.7720 - val_loss: 0.3935 - val_auc: 0.7945\n",
      "Epoch 00008: early stopping\n",
      "0.7945191132203793\n",
      "Train on 587999 samples, validate on 12001 samples\n",
      "Epoch 1/100\n",
      "587999/587999 [==============================] - 34s 58us/sample - loss: 0.4699 - auc: 0.6897 - val_loss: 0.4083 - val_auc: 0.7869\n",
      "Epoch 2/100\n",
      "587999/587999 [==============================] - 21s 36us/sample - loss: 0.4158 - auc: 0.7576 - val_loss: 0.3968 - val_auc: 0.7917\n",
      "Epoch 3/100\n",
      "587999/587999 [==============================] - 22s 37us/sample - loss: 0.4128 - auc: 0.7632 - val_loss: 0.3964 - val_auc: 0.7946\n",
      "Epoch 4/100\n",
      "587999/587999 [==============================] - 22s 37us/sample - loss: 0.4106 - auc: 0.7665 - val_loss: 0.3978 - val_auc: 0.7941\n",
      "Epoch 5/100\n",
      "587999/587999 [==============================] - 23s 39us/sample - loss: 0.4100 - auc: 0.7676 - val_loss: 0.3993 - val_auc: 0.7943\n",
      "Epoch 6/100\n",
      "587776/587999 [============================>.] - ETA: 0s - loss: 0.4091 - auc: 0.7690\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "587999/587999 [==============================] - 23s 39us/sample - loss: 0.4090 - auc: 0.7690 - val_loss: 0.3949 - val_auc: 0.7939\n",
      "Epoch 7/100\n",
      "587999/587999 [==============================] - 23s 39us/sample - loss: 0.4071 - auc: 0.7715 - val_loss: 0.3976 - val_auc: 0.7942\n",
      "Epoch 8/100\n",
      "586752/587999 [============================>.] - ETA: 0s - loss: 0.4070 - auc: 0.7715Restoring model weights from the end of the best epoch.\n",
      "587999/587999 [==============================] - 24s 41us/sample - loss: 0.4070 - auc: 0.7716 - val_loss: 0.3943 - val_auc: 0.7941\n",
      "Epoch 00008: early stopping\n",
      "0.7932964454736495\n",
      "Train on 587999 samples, validate on 12001 samples\n",
      "Epoch 1/100\n",
      "587999/587999 [==============================] - 30s 51us/sample - loss: 0.4694 - auc: 0.6882 - val_loss: 0.4070 - val_auc: 0.7754\n",
      "Epoch 2/100\n",
      "587999/587999 [==============================] - 24s 41us/sample - loss: 0.4165 - auc: 0.7566 - val_loss: 0.4056 - val_auc: 0.7771\n",
      "Epoch 3/100\n",
      "587999/587999 [==============================] - 21s 35us/sample - loss: 0.4120 - auc: 0.7643 - val_loss: 0.4057 - val_auc: 0.7779\n",
      "Epoch 4/100\n",
      "587999/587999 [==============================] - 20s 34us/sample - loss: 0.4106 - auc: 0.7665 - val_loss: 0.4049 - val_auc: 0.7781\n",
      "Epoch 5/100\n",
      "587999/587999 [==============================] - 20s 34us/sample - loss: 0.4097 - auc: 0.7679 - val_loss: 0.4037 - val_auc: 0.7785\n",
      "Epoch 6/100\n",
      "587999/587999 [==============================] - 20s 34us/sample - loss: 0.4088 - auc: 0.7694 - val_loss: 0.4044 - val_auc: 0.7784\n",
      "Epoch 7/100\n",
      "587999/587999 [==============================] - 20s 34us/sample - loss: 0.4083 - auc: 0.7702 - val_loss: 0.4034 - val_auc: 0.7792\n",
      "Epoch 8/100\n",
      "587999/587999 [==============================] - 20s 34us/sample - loss: 0.4075 - auc: 0.7715 - val_loss: 0.4032 - val_auc: 0.7784\n",
      "Epoch 9/100\n",
      "587999/587999 [==============================] - 20s 34us/sample - loss: 0.4074 - auc: 0.7716 - val_loss: 0.4030 - val_auc: 0.7785\n",
      "Epoch 10/100\n",
      "587776/587999 [============================>.] - ETA: 0s - loss: 0.4070 - auc: 0.7718Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "587999/587999 [==============================] - 20s 34us/sample - loss: 0.4071 - auc: 0.7718 - val_loss: 0.4035 - val_auc: 0.7787\n",
      "Epoch 00010: early stopping\n",
      "0.7772665515609221\n",
      "Train on 587999 samples, validate on 12001 samples\n",
      "Epoch 1/100\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4686 - auc: 0.6892 - val_loss: 0.4108 - val_auc: 0.7755\n",
      "Epoch 2/100\n",
      "587999/587999 [==============================] - 20s 34us/sample - loss: 0.4156 - auc: 0.7580 - val_loss: 0.4042 - val_auc: 0.7792\n",
      "Epoch 3/100\n",
      "587999/587999 [==============================] - 20s 34us/sample - loss: 0.4124 - auc: 0.7637 - val_loss: 0.4022 - val_auc: 0.7808\n",
      "Epoch 4/100\n",
      "587999/587999 [==============================] - 20s 34us/sample - loss: 0.4105 - auc: 0.7668 - val_loss: 0.4038 - val_auc: 0.7801\n",
      "Epoch 5/100\n",
      "587999/587999 [==============================] - 20s 34us/sample - loss: 0.4099 - auc: 0.7678 - val_loss: 0.4026 - val_auc: 0.7801\n",
      "Epoch 6/100\n",
      "586752/587999 [============================>.] - ETA: 0s - loss: 0.4089 - auc: 0.7695\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "587999/587999 [==============================] - 20s 34us/sample - loss: 0.4089 - auc: 0.7694 - val_loss: 0.4033 - val_auc: 0.7805\n",
      "Epoch 7/100\n",
      "587999/587999 [==============================] - 21s 35us/sample - loss: 0.4070 - auc: 0.7715 - val_loss: 0.4014 - val_auc: 0.7799\n",
      "Epoch 8/100\n",
      "587776/587999 [============================>.] - ETA: 0s - loss: 0.4065 - auc: 0.7723Restoring model weights from the end of the best epoch.\n",
      "587999/587999 [==============================] - 20s 35us/sample - loss: 0.4066 - auc: 0.7723 - val_loss: 0.4032 - val_auc: 0.7799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00008: early stopping\n",
      "0.7809423340659987\n",
      "Train on 587999 samples, validate on 12001 samples\n",
      "Epoch 1/100\n",
      "587999/587999 [==============================] - 23s 40us/sample - loss: 0.4670 - auc: 0.6915 - val_loss: 0.4071 - val_auc: 0.7818\n",
      "Epoch 2/100\n",
      "587999/587999 [==============================] - 20s 35us/sample - loss: 0.4164 - auc: 0.7566 - val_loss: 0.3986 - val_auc: 0.7848\n",
      "Epoch 3/100\n",
      "587999/587999 [==============================] - 24s 40us/sample - loss: 0.4126 - auc: 0.7632 - val_loss: 0.4033 - val_auc: 0.7846\n",
      "Epoch 4/100\n",
      "587999/587999 [==============================] - 23s 39us/sample - loss: 0.4108 - auc: 0.7661 - val_loss: 0.4009 - val_auc: 0.7857\n",
      "Epoch 5/100\n",
      "587999/587999 [==============================] - 23s 39us/sample - loss: 0.4094 - auc: 0.7684 - val_loss: 0.3977 - val_auc: 0.7855\n",
      "Epoch 6/100\n",
      "587999/587999 [==============================] - 27s 45us/sample - loss: 0.4089 - auc: 0.7692 - val_loss: 0.4021 - val_auc: 0.7859\n",
      "Epoch 7/100\n",
      "587999/587999 [==============================] - 22s 37us/sample - loss: 0.4082 - auc: 0.7703 - val_loss: 0.3978 - val_auc: 0.7858\n",
      "Epoch 8/100\n",
      "587999/587999 [==============================] - 19s 33us/sample - loss: 0.4079 - auc: 0.7704 - val_loss: 0.4022 - val_auc: 0.7857\n",
      "Epoch 9/100\n",
      "586752/587999 [============================>.] - ETA: 0s - loss: 0.4070 - auc: 0.7721\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "587999/587999 [==============================] - 18s 30us/sample - loss: 0.4070 - auc: 0.7720 - val_loss: 0.3997 - val_auc: 0.7857\n",
      "Epoch 10/100\n",
      "587999/587999 [==============================] - 17s 29us/sample - loss: 0.4062 - auc: 0.7726 - val_loss: 0.3994 - val_auc: 0.7861\n",
      "Epoch 11/100\n",
      "587776/587999 [============================>.] - ETA: 0s - loss: 0.4056 - auc: 0.7737Restoring model weights from the end of the best epoch.\n",
      "587999/587999 [==============================] - 18s 30us/sample - loss: 0.4056 - auc: 0.7737 - val_loss: 0.3991 - val_auc: 0.7852\n",
      "Epoch 00011: early stopping\n",
      "0.7870054155546425\n",
      "Train on 587999 samples, validate on 12001 samples\n",
      "Epoch 1/100\n",
      "587999/587999 [==============================] - 22s 37us/sample - loss: 0.4670 - auc: 0.6914 - val_loss: 0.4075 - val_auc: 0.7744\n",
      "Epoch 2/100\n",
      "587999/587999 [==============================] - 18s 31us/sample - loss: 0.4160 - auc: 0.7574 - val_loss: 0.4086 - val_auc: 0.7798\n",
      "Epoch 3/100\n",
      "587999/587999 [==============================] - 17s 29us/sample - loss: 0.4125 - auc: 0.7634 - val_loss: 0.4039 - val_auc: 0.7802\n",
      "Epoch 4/100\n",
      "587999/587999 [==============================] - 17s 28us/sample - loss: 0.4104 - auc: 0.7668 - val_loss: 0.4032 - val_auc: 0.7803\n",
      "Epoch 5/100\n",
      "587999/587999 [==============================] - 17s 30us/sample - loss: 0.4096 - auc: 0.7680 - val_loss: 0.4023 - val_auc: 0.7805\n",
      "Epoch 6/100\n",
      "587999/587999 [==============================] - 17s 29us/sample - loss: 0.4087 - auc: 0.7696 - val_loss: 0.4018 - val_auc: 0.7807\n",
      "Epoch 7/100\n",
      "587776/587999 [============================>.] - ETA: 0s - loss: 0.4085 - auc: 0.7697Restoring model weights from the end of the best epoch.\n",
      "587999/587999 [==============================] - 17s 29us/sample - loss: 0.4084 - auc: 0.7698 - val_loss: 0.4028 - val_auc: 0.7807\n",
      "Epoch 00007: early stopping\n",
      "0.7788205794909013\n",
      "Train on 587999 samples, validate on 12001 samples\n",
      "Epoch 1/100\n",
      "587999/587999 [==============================] - 22s 37us/sample - loss: 0.4699 - auc: 0.6897 - val_loss: 0.4069 - val_auc: 0.7829\n",
      "Epoch 2/100\n",
      "587999/587999 [==============================] - 17s 28us/sample - loss: 0.4161 - auc: 0.7571 - val_loss: 0.4002 - val_auc: 0.7853\n",
      "Epoch 3/100\n",
      "587999/587999 [==============================] - 18s 31us/sample - loss: 0.4122 - auc: 0.7642 - val_loss: 0.4011 - val_auc: 0.7864\n",
      "Epoch 4/100\n",
      "587999/587999 [==============================] - 18s 31us/sample - loss: 0.4105 - auc: 0.7667 - val_loss: 0.3995 - val_auc: 0.7886\n",
      "Epoch 5/100\n",
      "587999/587999 [==============================] - 17s 29us/sample - loss: 0.4095 - auc: 0.7683 - val_loss: 0.4046 - val_auc: 0.7881\n",
      "Epoch 6/100\n",
      "587999/587999 [==============================] - 18s 30us/sample - loss: 0.4091 - auc: 0.7691 - val_loss: 0.3988 - val_auc: 0.7864\n",
      "Epoch 7/100\n",
      "586752/587999 [============================>.] - ETA: 0s - loss: 0.4083 - auc: 0.7699\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "587999/587999 [==============================] - 21s 35us/sample - loss: 0.4083 - auc: 0.7698 - val_loss: 0.4012 - val_auc: 0.7866\n",
      "Epoch 8/100\n",
      "587999/587999 [==============================] - 21s 36us/sample - loss: 0.4068 - auc: 0.7717 - val_loss: 0.4027 - val_auc: 0.7869\n",
      "Epoch 9/100\n",
      "587776/587999 [============================>.] - ETA: 0s - loss: 0.4061 - auc: 0.7728Restoring model weights from the end of the best epoch.\n",
      "587999/587999 [==============================] - 21s 36us/sample - loss: 0.4061 - auc: 0.7729 - val_loss: 0.3988 - val_auc: 0.7871\n",
      "Epoch 00009: early stopping\n",
      "0.7869221021371398\n",
      "Train on 587999 samples, validate on 12001 samples\n",
      "Epoch 1/100\n",
      "587999/587999 [==============================] - 29s 49us/sample - loss: 0.4684 - auc: 0.6889 - val_loss: 0.4046 - val_auc: 0.7848\n",
      "Epoch 2/100\n",
      "587999/587999 [==============================] - 21s 36us/sample - loss: 0.4158 - auc: 0.7577 - val_loss: 0.4010 - val_auc: 0.7894\n",
      "Epoch 3/100\n",
      "587999/587999 [==============================] - 21s 36us/sample - loss: 0.4124 - auc: 0.7638 - val_loss: 0.3983 - val_auc: 0.7889\n",
      "Epoch 4/100\n",
      "587999/587999 [==============================] - 21s 35us/sample - loss: 0.4110 - auc: 0.7657 - val_loss: 0.3987 - val_auc: 0.7892\n",
      "Epoch 5/100\n",
      "586752/587999 [============================>.] - ETA: 0s - loss: 0.4097 - auc: 0.7679\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "587999/587999 [==============================] - 21s 36us/sample - loss: 0.4097 - auc: 0.7678 - val_loss: 0.4002 - val_auc: 0.7891\n",
      "Epoch 6/100\n",
      "587999/587999 [==============================] - 18s 31us/sample - loss: 0.4074 - auc: 0.7714 - val_loss: 0.3973 - val_auc: 0.7894\n",
      "Epoch 7/100\n",
      "587776/587999 [============================>.] - ETA: 0s - loss: 0.4069 - auc: 0.7719Restoring model weights from the end of the best epoch.\n",
      "587999/587999 [==============================] - 17s 30us/sample - loss: 0.4069 - auc: 0.7719 - val_loss: 0.3979 - val_auc: 0.7889\n",
      "Epoch 00007: early stopping\n",
      "0.7880983908647614\n",
      "Train on 587999 samples, validate on 12001 samples\n",
      "Epoch 1/100\n",
      "587999/587999 [==============================] - 29s 49us/sample - loss: 0.4676 - auc: 0.6916 - val_loss: 0.4061 - val_auc: 0.7548\n",
      "Epoch 2/100\n",
      "587999/587999 [==============================] - 22s 37us/sample - loss: 0.4163 - auc: 0.7569 - val_loss: 0.4001 - val_auc: 0.7588\n",
      "Epoch 3/100\n",
      "587999/587999 [==============================] - 21s 36us/sample - loss: 0.4125 - auc: 0.7634 - val_loss: 0.4013 - val_auc: 0.7596\n",
      "Epoch 4/100\n",
      "587999/587999 [==============================] - 21s 36us/sample - loss: 0.4104 - auc: 0.7671 - val_loss: 0.3990 - val_auc: 0.7584\n",
      "Epoch 5/100\n",
      "587999/587999 [==============================] - 18s 31us/sample - loss: 0.4094 - auc: 0.7687 - val_loss: 0.3988 - val_auc: 0.7600\n",
      "Epoch 6/100\n",
      "587999/587999 [==============================] - 17s 29us/sample - loss: 0.4088 - auc: 0.7694 - val_loss: 0.4032 - val_auc: 0.7599\n",
      "Epoch 7/100\n",
      "587999/587999 [==============================] - 20s 34us/sample - loss: 0.4081 - auc: 0.7706 - val_loss: 0.3994 - val_auc: 0.7587\n",
      "Epoch 8/100\n",
      "586752/587999 [============================>.] - ETA: 0s - loss: 0.4079 - auc: 0.7709\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "587999/587999 [==============================] - 23s 38us/sample - loss: 0.4079 - auc: 0.7709 - val_loss: 0.4028 - val_auc: 0.7586\n",
      "Epoch 9/100\n",
      "587999/587999 [==============================] - 21s 35us/sample - loss: 0.4068 - auc: 0.7720 - val_loss: 0.3989 - val_auc: 0.7586\n",
      "Epoch 10/100\n",
      "586752/587999 [============================>.] - ETA: 0s - loss: 0.4063 - auc: 0.7727Restoring model weights from the end of the best epoch.\n",
      "587999/587999 [==============================] - 33s 56us/sample - loss: 0.4063 - auc: 0.7727 - val_loss: 0.3993 - val_auc: 0.7590\n",
      "Epoch 00010: early stopping\n",
      "0.7852557425347118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 587999 samples, validate on 12001 samples\n",
      "Epoch 1/100\n",
      "587999/587999 [==============================] - 32s 55us/sample - loss: 0.4726 - auc: 0.6858 - val_loss: 0.4035 - val_auc: 0.7803\n",
      "Epoch 2/100\n",
      "587999/587999 [==============================] - 25s 43us/sample - loss: 0.4158 - auc: 0.7578 - val_loss: 0.4003 - val_auc: 0.7838\n",
      "Epoch 3/100\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4123 - auc: 0.7637 - val_loss: 0.3990 - val_auc: 0.7842\n",
      "Epoch 4/100\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4111 - auc: 0.7661 - val_loss: 0.4000 - val_auc: 0.7852\n",
      "Epoch 5/100\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4100 - auc: 0.7676 - val_loss: 0.3981 - val_auc: 0.7849\n",
      "Epoch 6/100\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4091 - auc: 0.7689 - val_loss: 0.4069 - val_auc: 0.7852\n",
      "Epoch 7/100\n",
      "587776/587999 [============================>.] - ETA: 0s - loss: 0.4084 - auc: 0.7700\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4083 - auc: 0.7700 - val_loss: 0.3980 - val_auc: 0.7844\n",
      "Epoch 8/100\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4064 - auc: 0.7724 - val_loss: 0.3988 - val_auc: 0.7845\n",
      "Epoch 9/100\n",
      "587776/587999 [============================>.] - ETA: 0s - loss: 0.4059 - auc: 0.7732Restoring model weights from the end of the best epoch.\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4059 - auc: 0.7732 - val_loss: 0.3995 - val_auc: 0.7850\n",
      "Epoch 00009: early stopping\n",
      "0.7858726313963466\n",
      "Train on 587999 samples, validate on 12001 samples\n",
      "Epoch 1/100\n",
      "587999/587999 [==============================] - 32s 54us/sample - loss: 0.4684 - auc: 0.6897 - val_loss: 0.4084 - val_auc: 0.7600\n",
      "Epoch 2/100\n",
      "587999/587999 [==============================] - 24s 41us/sample - loss: 0.4158 - auc: 0.7574 - val_loss: 0.4028 - val_auc: 0.7678\n",
      "Epoch 3/100\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4118 - auc: 0.7645 - val_loss: 0.4034 - val_auc: 0.7627\n",
      "Epoch 4/100\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4112 - auc: 0.7657 - val_loss: 0.3987 - val_auc: 0.7624\n",
      "Epoch 5/100\n",
      "587776/587999 [============================>.] - ETA: 0s - loss: 0.4100 - auc: 0.7673\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4100 - auc: 0.7673 - val_loss: 0.4008 - val_auc: 0.7620\n",
      "Epoch 6/100\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4075 - auc: 0.7711 - val_loss: 0.3992 - val_auc: 0.7641\n",
      "Epoch 7/100\n",
      "587776/587999 [============================>.] - ETA: 0s - loss: 0.4071 - auc: 0.7715Restoring model weights from the end of the best epoch.\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4071 - auc: 0.7715 - val_loss: 0.3996 - val_auc: 0.7620\n",
      "Epoch 00007: early stopping\n",
      "0.7851724291172092\n",
      "Train on 587999 samples, validate on 12001 samples\n",
      "Epoch 1/100\n",
      "587999/587999 [==============================] - 31s 54us/sample - loss: 0.4689 - auc: 0.6891 - val_loss: 0.4012 - val_auc: 0.7922\n",
      "Epoch 2/100\n",
      "587999/587999 [==============================] - 25s 43us/sample - loss: 0.4161 - auc: 0.7571 - val_loss: 0.3947 - val_auc: 0.7944\n",
      "Epoch 3/100\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4122 - auc: 0.7641 - val_loss: 0.3964 - val_auc: 0.7963\n",
      "Epoch 4/100\n",
      "587999/587999 [==============================] - 24s 41us/sample - loss: 0.4111 - auc: 0.7659 - val_loss: 0.3940 - val_auc: 0.7966\n",
      "Epoch 5/100\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4101 - auc: 0.7675 - val_loss: 0.4044 - val_auc: 0.7966\n",
      "Epoch 6/100\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4091 - auc: 0.7691 - val_loss: 0.3976 - val_auc: 0.7959\n",
      "Epoch 7/100\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4085 - auc: 0.7699 - val_loss: 0.3923 - val_auc: 0.7969\n",
      "Epoch 8/100\n",
      "587776/587999 [============================>.] - ETA: 0s - loss: 0.4079 - auc: 0.7708Restoring model weights from the end of the best epoch.\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4079 - auc: 0.7707 - val_loss: 0.3965 - val_auc: 0.7959\n",
      "Epoch 00008: early stopping\n",
      "0.7944264236214436\n",
      "Train on 587999 samples, validate on 12001 samples\n",
      "Epoch 1/100\n",
      "587999/587999 [==============================] - 32s 54us/sample - loss: 0.4695 - auc: 0.6885 - val_loss: 0.4053 - val_auc: 0.7563\n",
      "Epoch 2/100\n",
      "587999/587999 [==============================] - 24s 41us/sample - loss: 0.4160 - auc: 0.7575 - val_loss: 0.4026 - val_auc: 0.7600\n",
      "Epoch 3/100\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4124 - auc: 0.7637 - val_loss: 0.3997 - val_auc: 0.7617\n",
      "Epoch 4/100\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4109 - auc: 0.7662 - val_loss: 0.3986 - val_auc: 0.7627\n",
      "Epoch 5/100\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4100 - auc: 0.7675 - val_loss: 0.3983 - val_auc: 0.7624\n",
      "Epoch 6/100\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4089 - auc: 0.7691 - val_loss: 0.3982 - val_auc: 0.7627\n",
      "Epoch 7/100\n",
      "587999/587999 [==============================] - 26s 44us/sample - loss: 0.4083 - auc: 0.7702 - val_loss: 0.3977 - val_auc: 0.7630\n",
      "Epoch 8/100\n",
      "587999/587999 [==============================] - 23s 40us/sample - loss: 0.4077 - auc: 0.7711 - val_loss: 0.3982 - val_auc: 0.7628\n",
      "Epoch 9/100\n",
      "587999/587999 [==============================] - 22s 38us/sample - loss: 0.4075 - auc: 0.7713 - val_loss: 0.4004 - val_auc: 0.7626\n",
      "Epoch 10/100\n",
      "587776/587999 [============================>.] - ETA: 0s - loss: 0.4073 - auc: 0.7716\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4073 - auc: 0.7715 - val_loss: 0.4018 - val_auc: 0.7627\n",
      "Epoch 11/100\n",
      "586752/587999 [============================>.] - ETA: 0s - loss: 0.4060 - auc: 0.7732Restoring model weights from the end of the best epoch.\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4060 - auc: 0.7732 - val_loss: 0.4003 - val_auc: 0.7630\n",
      "Epoch 00011: early stopping\n",
      "0.7847641431826401\n",
      "Train on 587999 samples, validate on 12001 samples\n",
      "Epoch 1/100\n",
      "587999/587999 [==============================] - 33s 56us/sample - loss: 0.4708 - auc: 0.6891 - val_loss: 0.4112 - val_auc: 0.7510\n",
      "Epoch 2/100\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4161 - auc: 0.7571 - val_loss: 0.4087 - val_auc: 0.7506\n",
      "Epoch 3/100\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4126 - auc: 0.7634 - val_loss: 0.4066 - val_auc: 0.7522\n",
      "Epoch 4/100\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4105 - auc: 0.7670 - val_loss: 0.4065 - val_auc: 0.7518\n",
      "Epoch 5/100\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4098 - auc: 0.7682 - val_loss: 0.4066 - val_auc: 0.7535\n",
      "Epoch 6/100\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4085 - auc: 0.7700 - val_loss: 0.4071 - val_auc: 0.7528\n",
      "Epoch 7/100\n",
      "587999/587999 [==============================] - 24s 41us/sample - loss: 0.4082 - auc: 0.7705 - val_loss: 0.4049 - val_auc: 0.7520\n",
      "Epoch 8/100\n",
      "587776/587999 [============================>.] - ETA: 0s - loss: 0.4081 - auc: 0.7705\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "587999/587999 [==============================] - 24s 41us/sample - loss: 0.4081 - auc: 0.7705 - val_loss: 0.4051 - val_auc: 0.7518\n",
      "Epoch 9/100\n",
      "587999/587999 [==============================] - 25s 43us/sample - loss: 0.4065 - auc: 0.7724 - val_loss: 0.4065 - val_auc: 0.7522\n",
      "Epoch 10/100\n",
      "587776/587999 [============================>.] - ETA: 0s - loss: 0.4060 - auc: 0.7730Restoring model weights from the end of the best epoch.\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4060 - auc: 0.7730 - val_loss: 0.4053 - val_auc: 0.7518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00010: early stopping\n",
      "0.7760094816691775\n",
      "Train on 587999 samples, validate on 12001 samples\n",
      "Epoch 1/100\n",
      "587999/587999 [==============================] - 32s 55us/sample - loss: 0.4683 - auc: 0.6920 - val_loss: 0.4067 - val_auc: 0.7601\n",
      "Epoch 2/100\n",
      "587999/587999 [==============================] - 24s 41us/sample - loss: 0.4160 - auc: 0.7574 - val_loss: 0.4001 - val_auc: 0.7622\n",
      "Epoch 3/100\n",
      "587999/587999 [==============================] - 24s 41us/sample - loss: 0.4128 - auc: 0.7631 - val_loss: 0.4047 - val_auc: 0.7630\n",
      "Epoch 4/100\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4109 - auc: 0.7660 - val_loss: 0.3969 - val_auc: 0.7641\n",
      "Epoch 5/100\n",
      "587999/587999 [==============================] - 24s 42us/sample - loss: 0.4099 - auc: 0.7677 - val_loss: 0.3982 - val_auc: 0.7638\n",
      "Epoch 6/100\n",
      "587999/587999 [==============================] - 24s 42us/sample - loss: 0.4088 - auc: 0.7693 - val_loss: 0.3973 - val_auc: 0.7645\n",
      "Epoch 7/100\n",
      "587999/587999 [==============================] - 24s 41us/sample - loss: 0.4087 - auc: 0.7697 - val_loss: 0.3973 - val_auc: 0.7630\n",
      "Epoch 8/100\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4079 - auc: 0.7709 - val_loss: 0.3972 - val_auc: 0.7632\n",
      "Epoch 9/100\n",
      "587776/587999 [============================>.] - ETA: 0s - loss: 0.4076 - auc: 0.7710Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4076 - auc: 0.7710 - val_loss: 0.3973 - val_auc: 0.7637\n",
      "Epoch 00009: early stopping\n",
      "0.7891330102816787\n",
      "Train on 587999 samples, validate on 12001 samples\n",
      "Epoch 1/100\n",
      "587999/587999 [==============================] - 32s 54us/sample - loss: 0.4695 - auc: 0.6861 - val_loss: 0.4046 - val_auc: 0.7578\n",
      "Epoch 2/100\n",
      "587999/587999 [==============================] - 24s 42us/sample - loss: 0.4158 - auc: 0.7578 - val_loss: 0.4012 - val_auc: 0.7625\n",
      "Epoch 3/100\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4128 - auc: 0.7628 - val_loss: 0.3994 - val_auc: 0.7628\n",
      "Epoch 4/100\n",
      "587999/587999 [==============================] - 24s 41us/sample - loss: 0.4109 - auc: 0.7664 - val_loss: 0.4030 - val_auc: 0.7633\n",
      "Epoch 5/100\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4097 - auc: 0.7680 - val_loss: 0.4022 - val_auc: 0.7625\n",
      "Epoch 6/100\n",
      "587999/587999 [==============================] - 24s 41us/sample - loss: 0.4091 - auc: 0.7692 - val_loss: 0.4001 - val_auc: 0.7611\n",
      "Epoch 7/100\n",
      "586752/587999 [============================>.] - ETA: 0s - loss: 0.4086 - auc: 0.7696Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "587999/587999 [==============================] - 24s 41us/sample - loss: 0.4086 - auc: 0.7696 - val_loss: 0.3991 - val_auc: 0.7628\n",
      "Epoch 00007: early stopping\n",
      "0.7845713497293774\n",
      "Train on 587999 samples, validate on 12001 samples\n",
      "Epoch 1/100\n",
      "587999/587999 [==============================] - 32s 55us/sample - loss: 0.4716 - auc: 0.6859 - val_loss: 0.4099 - val_auc: 0.7597\n",
      "Epoch 2/100\n",
      "587999/587999 [==============================] - 24s 41us/sample - loss: 0.4161 - auc: 0.7572 - val_loss: 0.3987 - val_auc: 0.7647\n",
      "Epoch 3/100\n",
      "587999/587999 [==============================] - 24s 42us/sample - loss: 0.4123 - auc: 0.7639 - val_loss: 0.3990 - val_auc: 0.7653\n",
      "Epoch 4/100\n",
      "587999/587999 [==============================] - 24s 42us/sample - loss: 0.4108 - auc: 0.7664 - val_loss: 0.3978 - val_auc: 0.7655\n",
      "Epoch 5/100\n",
      "587999/587999 [==============================] - 24s 41us/sample - loss: 0.4094 - auc: 0.7686 - val_loss: 0.3961 - val_auc: 0.7655\n",
      "Epoch 6/100\n",
      "587999/587999 [==============================] - 24s 41us/sample - loss: 0.4095 - auc: 0.7683 - val_loss: 0.3994 - val_auc: 0.7648\n",
      "Epoch 7/100\n",
      "587776/587999 [============================>.] - ETA: 0s - loss: 0.4081 - auc: 0.7705Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "587999/587999 [==============================] - 24s 41us/sample - loss: 0.4081 - auc: 0.7704 - val_loss: 0.4013 - val_auc: 0.7643\n",
      "Epoch 00007: early stopping\n",
      "0.7887183823071136\n",
      "Train on 587999 samples, validate on 12001 samples\n",
      "Epoch 1/100\n",
      "587999/587999 [==============================] - 32s 55us/sample - loss: 0.4695 - auc: 0.6886 - val_loss: 0.4056 - val_auc: 0.7619\n",
      "Epoch 2/100\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4163 - auc: 0.7566 - val_loss: 0.4016 - val_auc: 0.7633\n",
      "Epoch 3/100\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4121 - auc: 0.7645 - val_loss: 0.3998 - val_auc: 0.7630\n",
      "Epoch 4/100\n",
      "587999/587999 [==============================] - 24s 41us/sample - loss: 0.4106 - auc: 0.7667 - val_loss: 0.3991 - val_auc: 0.7645\n",
      "Epoch 5/100\n",
      "587999/587999 [==============================] - 24s 41us/sample - loss: 0.4098 - auc: 0.7679 - val_loss: 0.3992 - val_auc: 0.7636\n",
      "Epoch 6/100\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4084 - auc: 0.7701 - val_loss: 0.3980 - val_auc: 0.7638\n",
      "Epoch 7/100\n",
      "586752/587999 [============================>.] - ETA: 0s - loss: 0.4086 - auc: 0.7700\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4086 - auc: 0.7699 - val_loss: 0.3989 - val_auc: 0.7633\n",
      "Epoch 8/100\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4069 - auc: 0.7718 - val_loss: 0.3987 - val_auc: 0.7642\n",
      "Epoch 9/100\n",
      "587776/587999 [============================>.] - ETA: 0s - loss: 0.4064 - auc: 0.7725Restoring model weights from the end of the best epoch.\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4064 - auc: 0.7724 - val_loss: 0.4026 - val_auc: 0.7635\n",
      "Epoch 00009: early stopping\n",
      "0.7873523114545729\n",
      "Train on 587999 samples, validate on 12001 samples\n",
      "Epoch 1/100\n",
      "587999/587999 [==============================] - 31s 52us/sample - loss: 0.4680 - auc: 0.6911 - val_loss: 0.4112 - val_auc: 0.7539\n",
      "Epoch 2/100\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4160 - auc: 0.7575 - val_loss: 0.4093 - val_auc: 0.7547\n",
      "Epoch 3/100\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4126 - auc: 0.7632 - val_loss: 0.4029 - val_auc: 0.7544\n",
      "Epoch 4/100\n",
      "587999/587999 [==============================] - 24s 41us/sample - loss: 0.4102 - auc: 0.7674 - val_loss: 0.4048 - val_auc: 0.7548\n",
      "Epoch 5/100\n",
      "587999/587999 [==============================] - 24s 40us/sample - loss: 0.4096 - auc: 0.7685 - val_loss: 0.4053 - val_auc: 0.7555\n",
      "Epoch 6/100\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4088 - auc: 0.7695 - val_loss: 0.4044 - val_auc: 0.7550\n",
      "Epoch 7/100\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4084 - auc: 0.7700 - val_loss: 0.4032 - val_auc: 0.7547\n",
      "Epoch 8/100\n",
      "586752/587999 [============================>.] - ETA: 0s - loss: 0.4080 - auc: 0.7707\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "587999/587999 [==============================] - 24s 42us/sample - loss: 0.4080 - auc: 0.7707 - val_loss: 0.4027 - val_auc: 0.7552\n",
      "Epoch 9/100\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4065 - auc: 0.7723 - val_loss: 0.4029 - val_auc: 0.7545\n",
      "Epoch 10/100\n",
      "586752/587999 [============================>.] - ETA: 0s - loss: 0.4055 - auc: 0.7739Restoring model weights from the end of the best epoch.\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4056 - auc: 0.7740 - val_loss: 0.4036 - val_auc: 0.7543\n",
      "Epoch 00010: early stopping\n",
      "0.7780805227373997\n",
      "Train on 587999 samples, validate on 12001 samples\n",
      "Epoch 1/100\n",
      "587999/587999 [==============================] - 32s 54us/sample - loss: 0.4678 - auc: 0.6895 - val_loss: 0.4153 - val_auc: 0.7527\n",
      "Epoch 2/100\n",
      "587999/587999 [==============================] - 25s 42us/sample - loss: 0.4157 - auc: 0.7576 - val_loss: 0.4075 - val_auc: 0.7530\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587999/587999 [==============================] - 23s 39us/sample - loss: 0.4124 - auc: 0.7639 - val_loss: 0.4050 - val_auc: 0.7533\n",
      "Epoch 4/100\n",
      "587999/587999 [==============================] - 23s 39us/sample - loss: 0.4107 - auc: 0.7668 - val_loss: 0.4046 - val_auc: 0.7545\n",
      "Epoch 5/100\n",
      "587999/587999 [==============================] - 23s 39us/sample - loss: 0.4099 - auc: 0.7678 - val_loss: 0.4033 - val_auc: 0.7544\n",
      "Epoch 6/100\n",
      "587999/587999 [==============================] - 23s 39us/sample - loss: 0.4089 - auc: 0.7693 - val_loss: 0.4053 - val_auc: 0.7542\n",
      "Epoch 7/100\n",
      "586752/587999 [============================>.] - ETA: 0s - loss: 0.4082 - auc: 0.7704\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "587999/587999 [==============================] - 23s 39us/sample - loss: 0.4082 - auc: 0.7703 - val_loss: 0.4041 - val_auc: 0.7544\n",
      "Epoch 8/100\n",
      "587999/587999 [==============================] - 23s 39us/sample - loss: 0.4067 - auc: 0.7722 - val_loss: 0.4060 - val_auc: 0.7540\n",
      "Epoch 9/100\n",
      "586752/587999 [============================>.] - ETA: 0s - loss: 0.4065 - auc: 0.7723Restoring model weights from the end of the best epoch.\n",
      "587999/587999 [==============================] - 23s 39us/sample - loss: 0.4065 - auc: 0.7724 - val_loss: 0.4024 - val_auc: 0.7545\n",
      "Epoch 00009: early stopping\n",
      "0.77826660914117\n",
      "Train on 587999 samples, validate on 12001 samples\n",
      "Epoch 1/100\n",
      "587999/587999 [==============================] - 31s 52us/sample - loss: 0.4704 - auc: 0.6882 - val_loss: 0.4090 - val_auc: 0.7562\n",
      "Epoch 2/100\n",
      "587999/587999 [==============================] - 23s 39us/sample - loss: 0.4158 - auc: 0.7577 - val_loss: 0.4012 - val_auc: 0.7594\n",
      "Epoch 3/100\n",
      "587999/587999 [==============================] - 23s 38us/sample - loss: 0.4124 - auc: 0.7637 - val_loss: 0.4002 - val_auc: 0.7611\n",
      "Epoch 4/100\n",
      "587999/587999 [==============================] - 22s 38us/sample - loss: 0.4108 - auc: 0.7666 - val_loss: 0.4019 - val_auc: 0.7606\n",
      "Epoch 5/100\n",
      "587999/587999 [==============================] - 23s 39us/sample - loss: 0.4100 - auc: 0.7676 - val_loss: 0.3982 - val_auc: 0.7627\n",
      "Epoch 6/100\n",
      "587999/587999 [==============================] - 23s 39us/sample - loss: 0.4087 - auc: 0.7695 - val_loss: 0.3971 - val_auc: 0.7618\n",
      "Epoch 7/100\n",
      "587999/587999 [==============================] - 23s 39us/sample - loss: 0.4089 - auc: 0.7691 - val_loss: 0.3971 - val_auc: 0.7617\n",
      "Epoch 8/100\n",
      "586752/587999 [============================>.] - ETA: 0s - loss: 0.4079 - auc: 0.7710\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "587999/587999 [==============================] - 23s 39us/sample - loss: 0.4079 - auc: 0.7710 - val_loss: 0.3992 - val_auc: 0.7613\n",
      "Epoch 9/100\n",
      "587999/587999 [==============================] - 23s 40us/sample - loss: 0.4063 - auc: 0.7729 - val_loss: 0.3990 - val_auc: 0.7612\n",
      "Epoch 10/100\n",
      "587776/587999 [============================>.] - ETA: 0s - loss: 0.4060 - auc: 0.7731Restoring model weights from the end of the best epoch.\n",
      "587999/587999 [==============================] - 23s 39us/sample - loss: 0.4059 - auc: 0.7732 - val_loss: 0.3987 - val_auc: 0.7611\n",
      "Epoch 00010: early stopping\n",
      "0.7882121141359144\n",
      "Train on 587999 samples, validate on 12001 samples\n",
      "Epoch 1/100\n",
      "587999/587999 [==============================] - 31s 52us/sample - loss: 0.4708 - auc: 0.6882 - val_loss: 0.4038 - val_auc: 0.7378\n",
      "Epoch 2/100\n",
      "587999/587999 [==============================] - 23s 39us/sample - loss: 0.4162 - auc: 0.7569 - val_loss: 0.3975 - val_auc: 0.7403\n",
      "Epoch 3/100\n",
      "587999/587999 [==============================] - 23s 39us/sample - loss: 0.4119 - auc: 0.7644 - val_loss: 0.3974 - val_auc: 0.7414\n",
      "Epoch 4/100\n",
      "587999/587999 [==============================] - 23s 39us/sample - loss: 0.4108 - auc: 0.7662 - val_loss: 0.4041 - val_auc: 0.7402\n",
      "Epoch 5/100\n",
      "587999/587999 [==============================] - 23s 39us/sample - loss: 0.4092 - auc: 0.7687 - val_loss: 0.3988 - val_auc: 0.7404\n",
      "Epoch 6/100\n",
      "587776/587999 [============================>.] - ETA: 0s - loss: 0.4089 - auc: 0.7693\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "587999/587999 [==============================] - 23s 39us/sample - loss: 0.4089 - auc: 0.7693 - val_loss: 0.3979 - val_auc: 0.7406\n",
      "Epoch 7/100\n",
      "587999/587999 [==============================] - 23s 39us/sample - loss: 0.4070 - auc: 0.7716 - val_loss: 0.3962 - val_auc: 0.7409\n",
      "Epoch 8/100\n",
      "586752/587999 [============================>.] - ETA: 0s - loss: 0.4065 - auc: 0.7725Restoring model weights from the end of the best epoch.\n",
      "587999/587999 [==============================] - 22s 38us/sample - loss: 0.4065 - auc: 0.7726 - val_loss: 0.3965 - val_auc: 0.7409\n",
      "Epoch 00008: early stopping\n",
      "0.7894951681411682\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "588000/588000 [==============================] - 31s 52us/sample - loss: 0.4688 - auc: 0.6890 - val_loss: 0.4080 - val_auc: 0.7564\n",
      "Epoch 2/100\n",
      "588000/588000 [==============================] - 21s 36us/sample - loss: 0.4162 - auc: 0.7570 - val_loss: 0.4043 - val_auc: 0.7600\n",
      "Epoch 3/100\n",
      "588000/588000 [==============================] - 23s 38us/sample - loss: 0.4124 - auc: 0.7634 - val_loss: 0.4086 - val_auc: 0.7598\n",
      "Epoch 4/100\n",
      "588000/588000 [==============================] - 26s 44us/sample - loss: 0.4108 - auc: 0.7666 - val_loss: 0.3978 - val_auc: 0.7615\n",
      "Epoch 5/100\n",
      "588000/588000 [==============================] - 25s 43us/sample - loss: 0.4100 - auc: 0.7677 - val_loss: 0.3982 - val_auc: 0.7604\n",
      "Epoch 6/100\n",
      "588000/588000 [==============================] - 25s 42us/sample - loss: 0.4093 - auc: 0.7688 - val_loss: 0.3971 - val_auc: 0.7613\n",
      "Epoch 7/100\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4083 - auc: 0.7704\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "588000/588000 [==============================] - 25s 42us/sample - loss: 0.4083 - auc: 0.7705 - val_loss: 0.3976 - val_auc: 0.7613\n",
      "Epoch 8/100\n",
      "588000/588000 [==============================] - 25s 42us/sample - loss: 0.4069 - auc: 0.7717 - val_loss: 0.4027 - val_auc: 0.7600\n",
      "Epoch 9/100\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4063 - auc: 0.7728Restoring model weights from the end of the best epoch.\n",
      "588000/588000 [==============================] - 25s 42us/sample - loss: 0.4063 - auc: 0.7728 - val_loss: 0.3986 - val_auc: 0.7606\n",
      "Epoch 00009: early stopping\n",
      "0.7851373530616295\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "588000/588000 [==============================] - 32s 55us/sample - loss: 0.4707 - auc: 0.6875 - val_loss: 0.4084 - val_auc: 0.7418\n",
      "Epoch 2/100\n",
      "588000/588000 [==============================] - 25s 42us/sample - loss: 0.4161 - auc: 0.7572 - val_loss: 0.3980 - val_auc: 0.7442\n",
      "Epoch 3/100\n",
      "588000/588000 [==============================] - 25s 42us/sample - loss: 0.4125 - auc: 0.7636 - val_loss: 0.3958 - val_auc: 0.7436\n",
      "Epoch 4/100\n",
      "588000/588000 [==============================] - 25s 42us/sample - loss: 0.4113 - auc: 0.7654 - val_loss: 0.3955 - val_auc: 0.7450\n",
      "Epoch 5/100\n",
      "588000/588000 [==============================] - 25s 42us/sample - loss: 0.4097 - auc: 0.7683 - val_loss: 0.3940 - val_auc: 0.7433\n",
      "Epoch 6/100\n",
      "588000/588000 [==============================] - 25s 42us/sample - loss: 0.4090 - auc: 0.7690 - val_loss: 0.3967 - val_auc: 0.7435\n",
      "Epoch 7/100\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4084 - auc: 0.7698Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "588000/588000 [==============================] - 24s 41us/sample - loss: 0.4084 - auc: 0.7698 - val_loss: 0.3952 - val_auc: 0.7439\n",
      "Epoch 00007: early stopping\n",
      "0.7921056795020368\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "588000/588000 [==============================] - 32s 55us/sample - loss: 0.4689 - auc: 0.6888 - val_loss: 0.4077 - val_auc: 0.7342\n",
      "Epoch 2/100\n",
      "588000/588000 [==============================] - 25s 42us/sample - loss: 0.4163 - auc: 0.7568 - val_loss: 0.4004 - val_auc: 0.7380\n",
      "Epoch 3/100\n",
      "588000/588000 [==============================] - 25s 43us/sample - loss: 0.4122 - auc: 0.7643 - val_loss: 0.4023 - val_auc: 0.7382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "588000/588000 [==============================] - 25s 42us/sample - loss: 0.4110 - auc: 0.7660 - val_loss: 0.4002 - val_auc: 0.7384\n",
      "Epoch 5/100\n",
      "588000/588000 [==============================] - 24s 42us/sample - loss: 0.4096 - auc: 0.7684 - val_loss: 0.3978 - val_auc: 0.7388\n",
      "Epoch 6/100\n",
      "588000/588000 [==============================] - 24s 41us/sample - loss: 0.4088 - auc: 0.7698 - val_loss: 0.3997 - val_auc: 0.7375\n",
      "Epoch 7/100\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4088 - auc: 0.7695Restoring model weights from the end of the best epoch.\n",
      "588000/588000 [==============================] - 24s 41us/sample - loss: 0.4088 - auc: 0.7694 - val_loss: 0.4122 - val_auc: 0.7373\n",
      "Epoch 00007: early stopping\n",
      "0.7869795545668321\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "588000/588000 [==============================] - 32s 55us/sample - loss: 0.4690 - auc: 0.6903 - val_loss: 0.4064 - val_auc: 0.7593\n",
      "Epoch 2/100\n",
      "588000/588000 [==============================] - 25s 42us/sample - loss: 0.4159 - auc: 0.7572 - val_loss: 0.4021 - val_auc: 0.7555\n",
      "Epoch 3/100\n",
      "588000/588000 [==============================] - 25s 42us/sample - loss: 0.4124 - auc: 0.7639 - val_loss: 0.3989 - val_auc: 0.7597\n",
      "Epoch 4/100\n",
      "588000/588000 [==============================] - 24s 41us/sample - loss: 0.4106 - auc: 0.7665 - val_loss: 0.4006 - val_auc: 0.7582\n",
      "Epoch 5/100\n",
      "588000/588000 [==============================] - 24s 41us/sample - loss: 0.4099 - auc: 0.7676 - val_loss: 0.3990 - val_auc: 0.7606\n",
      "Epoch 6/100\n",
      "588000/588000 [==============================] - 24s 41us/sample - loss: 0.4089 - auc: 0.7696 - val_loss: 0.4009 - val_auc: 0.7578\n",
      "Epoch 7/100\n",
      "588000/588000 [==============================] - 24s 41us/sample - loss: 0.4084 - auc: 0.7699 - val_loss: 0.3997 - val_auc: 0.7600\n",
      "Epoch 8/100\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4082 - auc: 0.7707\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "588000/588000 [==============================] - 24s 40us/sample - loss: 0.4082 - auc: 0.7707 - val_loss: 0.3997 - val_auc: 0.7589\n",
      "Epoch 9/100\n",
      "588000/588000 [==============================] - 25s 42us/sample - loss: 0.4066 - auc: 0.7724 - val_loss: 0.4004 - val_auc: 0.7593\n",
      "Epoch 10/100\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4058 - auc: 0.7735Restoring model weights from the end of the best epoch.\n",
      "588000/588000 [==============================] - 24s 42us/sample - loss: 0.4059 - auc: 0.7734 - val_loss: 0.4021 - val_auc: 0.7593\n",
      "Epoch 00010: early stopping\n",
      "0.7850815502136165\n",
      "Train on 588001 samples, validate on 11999 samples\n",
      "Epoch 1/100\n",
      "588001/588001 [==============================] - 32s 55us/sample - loss: 0.4695 - auc: 0.6902 - val_loss: 0.4040 - val_auc: 0.7390\n",
      "Epoch 2/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4162 - auc: 0.7569 - val_loss: 0.3952 - val_auc: 0.7428\n",
      "Epoch 3/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4127 - auc: 0.7632 - val_loss: 0.3968 - val_auc: 0.7443\n",
      "Epoch 4/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4111 - auc: 0.7658 - val_loss: 0.3968 - val_auc: 0.7441\n",
      "Epoch 5/100\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4096 - auc: 0.7682 - val_loss: 0.3941 - val_auc: 0.7446\n",
      "Epoch 6/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4095 - auc: 0.7682 - val_loss: 0.3952 - val_auc: 0.7445\n",
      "Epoch 7/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4083 - auc: 0.7704 - val_loss: 0.3939 - val_auc: 0.7441\n",
      "Epoch 8/100\n",
      "587776/588001 [============================>.] - ETA: 0s - loss: 0.4081 - auc: 0.7702Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4081 - auc: 0.7702 - val_loss: 0.3954 - val_auc: 0.7431\n",
      "Epoch 00008: early stopping\n",
      "0.791700323000371\n",
      "Train on 588001 samples, validate on 11999 samples\n",
      "Epoch 1/100\n",
      "588001/588001 [==============================] - 32s 55us/sample - loss: 0.4693 - auc: 0.6902 - val_loss: 0.4067 - val_auc: 0.7508\n",
      "Epoch 2/100\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4162 - auc: 0.7571 - val_loss: 0.4071 - val_auc: 0.7533\n",
      "Epoch 3/100\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4124 - auc: 0.7636 - val_loss: 0.4040 - val_auc: 0.7538\n",
      "Epoch 4/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4108 - auc: 0.7663 - val_loss: 0.4021 - val_auc: 0.7540\n",
      "Epoch 5/100\n",
      "588001/588001 [==============================] - 24s 40us/sample - loss: 0.4097 - auc: 0.7680 - val_loss: 0.4020 - val_auc: 0.7538\n",
      "Epoch 6/100\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4089 - auc: 0.7691 - val_loss: 0.4046 - val_auc: 0.7532\n",
      "Epoch 7/100\n",
      "587776/588001 [============================>.] - ETA: 0s - loss: 0.4083 - auc: 0.7704Restoring model weights from the end of the best epoch.\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4083 - auc: 0.7704 - val_loss: 0.4019 - val_auc: 0.7542\n",
      "Epoch 00007: early stopping\n",
      "0.7788785038537358\n",
      "Train on 588001 samples, validate on 11999 samples\n",
      "Epoch 1/100\n",
      "588001/588001 [==============================] - 32s 55us/sample - loss: 0.4684 - auc: 0.6890 - val_loss: 0.4059 - val_auc: 0.7671\n",
      "Epoch 2/100\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4163 - auc: 0.7568 - val_loss: 0.4049 - val_auc: 0.7669\n",
      "Epoch 3/100\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4126 - auc: 0.7633 - val_loss: 0.4043 - val_auc: 0.7678\n",
      "Epoch 4/100\n",
      "588001/588001 [==============================] - 26s 44us/sample - loss: 0.4106 - auc: 0.7666 - val_loss: 0.4036 - val_auc: 0.7671\n",
      "Epoch 5/100\n",
      "588001/588001 [==============================] - 25s 43us/sample - loss: 0.4096 - auc: 0.7683 - val_loss: 0.4025 - val_auc: 0.7673\n",
      "Epoch 6/100\n",
      "587776/588001 [============================>.] - ETA: 0s - loss: 0.4088 - auc: 0.7694Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4088 - auc: 0.7693 - val_loss: 0.4020 - val_auc: 0.7675\n",
      "Epoch 00006: early stopping\n",
      "0.7780009055368401\n",
      "Train on 588001 samples, validate on 11999 samples\n",
      "Epoch 1/100\n",
      "588001/588001 [==============================] - 33s 56us/sample - loss: 0.4685 - auc: 0.6908 - val_loss: 0.4044 - val_auc: 0.7612\n",
      "Epoch 2/100\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4162 - auc: 0.7570 - val_loss: 0.4012 - val_auc: 0.7646\n",
      "Epoch 3/100\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4128 - auc: 0.7632 - val_loss: 0.4001 - val_auc: 0.7650\n",
      "Epoch 4/100\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4107 - auc: 0.7664 - val_loss: 0.3985 - val_auc: 0.7651\n",
      "Epoch 5/100\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4097 - auc: 0.7678 - val_loss: 0.4011 - val_auc: 0.7643\n",
      "Epoch 6/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4090 - auc: 0.7695 - val_loss: 0.3993 - val_auc: 0.7652\n",
      "Epoch 7/100\n",
      "586752/588001 [============================>.] - ETA: 0s - loss: 0.4083 - auc: 0.7700Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4083 - auc: 0.7699 - val_loss: 0.4011 - val_auc: 0.7643\n",
      "Epoch 00007: early stopping\n",
      "0.7866417840335722\n",
      "Train on 588001 samples, validate on 11999 samples\n",
      "Epoch 1/100\n",
      "588001/588001 [==============================] - 32s 54us/sample - loss: 0.4689 - auc: 0.6902 - val_loss: 0.4025 - val_auc: 0.7601\n",
      "Epoch 2/100\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4160 - auc: 0.7571 - val_loss: 0.4006 - val_auc: 0.7605\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4121 - auc: 0.7642 - val_loss: 0.3985 - val_auc: 0.7611\n",
      "Epoch 4/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4106 - auc: 0.7668 - val_loss: 0.3963 - val_auc: 0.7627\n",
      "Epoch 5/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4096 - auc: 0.7680 - val_loss: 0.3975 - val_auc: 0.7622\n",
      "Epoch 6/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4092 - auc: 0.7686 - val_loss: 0.3999 - val_auc: 0.7619\n",
      "Epoch 7/100\n",
      "587776/588001 [============================>.] - ETA: 0s - loss: 0.4082 - auc: 0.7704\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4082 - auc: 0.7705 - val_loss: 0.3966 - val_auc: 0.7625\n",
      "Epoch 8/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4066 - auc: 0.7723 - val_loss: 0.3964 - val_auc: 0.7621\n",
      "Epoch 9/100\n",
      "586752/588001 [============================>.] - ETA: 0s - loss: 0.4061 - auc: 0.7730Restoring model weights from the end of the best epoch.\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4061 - auc: 0.7731 - val_loss: 0.3974 - val_auc: 0.7623\n",
      "Epoch 00009: early stopping\n",
      "0.7880358569945691\n",
      "Train on 588001 samples, validate on 11999 samples\n",
      "Epoch 1/100\n",
      "588001/588001 [==============================] - 33s 56us/sample - loss: 0.4686 - auc: 0.6886 - val_loss: 0.4099 - val_auc: 0.7511\n",
      "Epoch 2/100\n",
      "588001/588001 [==============================] - 24s 42us/sample - loss: 0.4164 - auc: 0.7565 - val_loss: 0.4060 - val_auc: 0.7554\n",
      "Epoch 3/100\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4123 - auc: 0.7639 - val_loss: 0.4012 - val_auc: 0.7567\n",
      "Epoch 4/100\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4108 - auc: 0.7665 - val_loss: 0.4016 - val_auc: 0.7572\n",
      "Epoch 5/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4101 - auc: 0.7676 - val_loss: 0.4012 - val_auc: 0.7573\n",
      "Epoch 6/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4091 - auc: 0.7688 - val_loss: 0.4004 - val_auc: 0.7565\n",
      "Epoch 7/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4080 - auc: 0.7707 - val_loss: 0.4030 - val_auc: 0.7553\n",
      "Epoch 8/100\n",
      "586752/588001 [============================>.] - ETA: 0s - loss: 0.4076 - auc: 0.7712Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "588001/588001 [==============================] - 25s 43us/sample - loss: 0.4076 - auc: 0.7712 - val_loss: 0.4024 - val_auc: 0.7556\n",
      "Epoch 00008: early stopping\n",
      "0.7812375971445733\n",
      "Train on 588001 samples, validate on 11999 samples\n",
      "Epoch 1/100\n",
      "588001/588001 [==============================] - 33s 55us/sample - loss: 0.4691 - auc: 0.6891 - val_loss: 0.4048 - val_auc: 0.7547\n",
      "Epoch 2/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4164 - auc: 0.7568 - val_loss: 0.4022 - val_auc: 0.7559\n",
      "Epoch 3/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4122 - auc: 0.7641 - val_loss: 0.4086 - val_auc: 0.7585\n",
      "Epoch 4/100\n",
      "588001/588001 [==============================] - 25s 43us/sample - loss: 0.4110 - auc: 0.7661 - val_loss: 0.4027 - val_auc: 0.7590\n",
      "Epoch 5/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4098 - auc: 0.7677 - val_loss: 0.4008 - val_auc: 0.7580\n",
      "Epoch 6/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4092 - auc: 0.7688 - val_loss: 0.4036 - val_auc: 0.7586\n",
      "Epoch 7/100\n",
      "587776/588001 [============================>.] - ETA: 0s - loss: 0.4087 - auc: 0.7695\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4087 - auc: 0.7696 - val_loss: 0.4007 - val_auc: 0.7583\n",
      "Epoch 8/100\n",
      "587776/588001 [============================>.] - ETA: 0s - loss: 0.4069 - auc: 0.7716Restoring model weights from the end of the best epoch.\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4069 - auc: 0.7715 - val_loss: 0.4019 - val_auc: 0.7589\n",
      "Epoch 00008: early stopping\n",
      "0.7834153411161295\n",
      "Train on 588001 samples, validate on 11999 samples\n",
      "Epoch 1/100\n",
      "588001/588001 [==============================] - 32s 55us/sample - loss: 0.4717 - auc: 0.6864 - val_loss: 0.4054 - val_auc: 0.7869\n",
      "Epoch 2/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4164 - auc: 0.7567 - val_loss: 0.3979 - val_auc: 0.7908\n",
      "Epoch 3/100\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4125 - auc: 0.7632 - val_loss: 0.3982 - val_auc: 0.7908\n",
      "Epoch 4/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4107 - auc: 0.7665 - val_loss: 0.3980 - val_auc: 0.7917\n",
      "Epoch 5/100\n",
      "588001/588001 [==============================] - 26s 44us/sample - loss: 0.4097 - auc: 0.7681 - val_loss: 0.3993 - val_auc: 0.7903\n",
      "Epoch 6/100\n",
      "588001/588001 [==============================] - 26s 44us/sample - loss: 0.4089 - auc: 0.7693 - val_loss: 0.3959 - val_auc: 0.7914\n",
      "Epoch 7/100\n",
      "587776/588001 [============================>.] - ETA: 0s - loss: 0.4081 - auc: 0.7706Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "588001/588001 [==============================] - 25s 43us/sample - loss: 0.4081 - auc: 0.7706 - val_loss: 0.3963 - val_auc: 0.7908\n",
      "Epoch 00007: early stopping\n",
      "0.7877152030943467\n",
      "Train on 588001 samples, validate on 11999 samples\n",
      "Epoch 1/100\n",
      "588001/588001 [==============================] - 31s 53us/sample - loss: 0.4683 - auc: 0.6916 - val_loss: 0.4055 - val_auc: 0.7867\n",
      "Epoch 2/100\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4159 - auc: 0.7574 - val_loss: 0.3980 - val_auc: 0.7893\n",
      "Epoch 3/100\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4124 - auc: 0.7637 - val_loss: 0.3965 - val_auc: 0.7913\n",
      "Epoch 4/100\n",
      "588001/588001 [==============================] - 24s 42us/sample - loss: 0.4109 - auc: 0.7662 - val_loss: 0.3958 - val_auc: 0.7921\n",
      "Epoch 5/100\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4100 - auc: 0.7677 - val_loss: 0.3964 - val_auc: 0.7922\n",
      "Epoch 6/100\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4091 - auc: 0.7689 - val_loss: 0.3980 - val_auc: 0.7919\n",
      "Epoch 7/100\n",
      "587776/588001 [============================>.] - ETA: 0s - loss: 0.4087 - auc: 0.7696\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4086 - auc: 0.7698 - val_loss: 0.3955 - val_auc: 0.7916\n",
      "Epoch 8/100\n",
      "588001/588001 [==============================] - 24s 42us/sample - loss: 0.4068 - auc: 0.7721 - val_loss: 0.3958 - val_auc: 0.7925\n",
      "Epoch 9/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4065 - auc: 0.7724 - val_loss: 0.3940 - val_auc: 0.7919\n",
      "Epoch 10/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4062 - auc: 0.7727 - val_loss: 0.3960 - val_auc: 0.7916\n",
      "Epoch 11/100\n",
      "587776/588001 [============================>.] - ETA: 0s - loss: 0.4058 - auc: 0.7737\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "588001/588001 [==============================] - 25s 43us/sample - loss: 0.4058 - auc: 0.7737 - val_loss: 0.3944 - val_auc: 0.7920\n",
      "Epoch 12/100\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4056 - auc: 0.7735 - val_loss: 0.3966 - val_auc: 0.7916\n",
      "Epoch 13/100\n",
      "587776/588001 [============================>.] - ETA: 0s - loss: 0.4055 - auc: 0.7737Restoring model weights from the end of the best epoch.\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4055 - auc: 0.7736 - val_loss: 0.3952 - val_auc: 0.7918\n",
      "Epoch 00013: early stopping\n",
      "0.7934710410359386\n",
      "Train on 588001 samples, validate on 11999 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "588001/588001 [==============================] - 32s 55us/sample - loss: 0.4688 - auc: 0.6903 - val_loss: 0.4102 - val_auc: 0.7821\n",
      "Epoch 2/100\n",
      "588001/588001 [==============================] - 24s 40us/sample - loss: 0.4157 - auc: 0.7581 - val_loss: 0.4028 - val_auc: 0.7877\n",
      "Epoch 3/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4121 - auc: 0.7641 - val_loss: 0.4029 - val_auc: 0.7846\n",
      "Epoch 4/100\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4109 - auc: 0.7663 - val_loss: 0.4022 - val_auc: 0.7856\n",
      "Epoch 5/100\n",
      "587776/588001 [============================>.] - ETA: 0s - loss: 0.4094 - auc: 0.7685\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4094 - auc: 0.7685 - val_loss: 0.3997 - val_auc: 0.7875\n",
      "Epoch 6/100\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4078 - auc: 0.7706 - val_loss: 0.4005 - val_auc: 0.7874\n",
      "Epoch 7/100\n",
      "587776/588001 [============================>.] - ETA: 0s - loss: 0.4068 - auc: 0.7719Restoring model weights from the end of the best epoch.\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4067 - auc: 0.7720 - val_loss: 0.3999 - val_auc: 0.7877\n",
      "Epoch 00007: early stopping\n",
      "0.7842398699343053\n",
      "Train on 588001 samples, validate on 11999 samples\n",
      "Epoch 1/100\n",
      "588001/588001 [==============================] - 32s 55us/sample - loss: 0.4696 - auc: 0.6886 - val_loss: 0.3975 - val_auc: 0.7889\n",
      "Epoch 2/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4163 - auc: 0.7570 - val_loss: 0.3936 - val_auc: 0.7926\n",
      "Epoch 3/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4128 - auc: 0.7629 - val_loss: 0.3960 - val_auc: 0.7926\n",
      "Epoch 4/100\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4111 - auc: 0.7658 - val_loss: 0.3942 - val_auc: 0.7930\n",
      "Epoch 5/100\n",
      "588001/588001 [==============================] - 23s 38us/sample - loss: 0.4094 - auc: 0.7684 - val_loss: 0.3922 - val_auc: 0.7935\n",
      "Epoch 6/100\n",
      "588001/588001 [==============================] - 20s 34us/sample - loss: 0.4099 - auc: 0.7675 - val_loss: 0.3965 - val_auc: 0.7934\n",
      "Epoch 7/100\n",
      "586752/588001 [============================>.] - ETA: 0s - loss: 0.4083 - auc: 0.7702Restoring model weights from the end of the best epoch.\n",
      "588001/588001 [==============================] - 19s 32us/sample - loss: 0.4083 - auc: 0.7703 - val_loss: 0.3930 - val_auc: 0.7927\n",
      "Epoch 00007: early stopping\n",
      "0.7938466133077394\n",
      "Train on 588001 samples, validate on 11999 samples\n",
      "Epoch 1/100\n",
      "588001/588001 [==============================] - 23s 40us/sample - loss: 0.4672 - auc: 0.6919 - val_loss: 0.4066 - val_auc: 0.7757\n",
      "Epoch 2/100\n",
      "588001/588001 [==============================] - 19s 32us/sample - loss: 0.4161 - auc: 0.7571 - val_loss: 0.4030 - val_auc: 0.7832\n",
      "Epoch 3/100\n",
      "588001/588001 [==============================] - 19s 32us/sample - loss: 0.4120 - auc: 0.7644 - val_loss: 0.4028 - val_auc: 0.7809\n",
      "Epoch 4/100\n",
      "588001/588001 [==============================] - 19s 32us/sample - loss: 0.4107 - auc: 0.7666 - val_loss: 0.4010 - val_auc: 0.7824\n",
      "Epoch 5/100\n",
      "586752/588001 [============================>.] - ETA: 0s - loss: 0.4094 - auc: 0.7684\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "588001/588001 [==============================] - 18s 31us/sample - loss: 0.4094 - auc: 0.7684 - val_loss: 0.4007 - val_auc: 0.7817\n",
      "Epoch 6/100\n",
      "588001/588001 [==============================] - 29s 50us/sample - loss: 0.4076 - auc: 0.7709 - val_loss: 0.4003 - val_auc: 0.7827\n",
      "Epoch 7/100\n",
      "587776/588001 [============================>.] - ETA: 0s - loss: 0.4072 - auc: 0.7714Restoring model weights from the end of the best epoch.\n",
      "588001/588001 [==============================] - 28s 47us/sample - loss: 0.4072 - auc: 0.7714 - val_loss: 0.4008 - val_auc: 0.7824\n",
      "Epoch 00007: early stopping\n",
      "0.7820277962741148\n",
      "Train on 588001 samples, validate on 11999 samples\n",
      "Epoch 1/100\n",
      "588001/588001 [==============================] - 34s 58us/sample - loss: 0.4694 - auc: 0.6885 - val_loss: 0.4098 - val_auc: 0.7864\n",
      "Epoch 2/100\n",
      "588001/588001 [==============================] - 25s 43us/sample - loss: 0.4159 - auc: 0.7573 - val_loss: 0.4053 - val_auc: 0.7915\n",
      "Epoch 3/100\n",
      "588001/588001 [==============================] - 26s 45us/sample - loss: 0.4124 - auc: 0.7638 - val_loss: 0.4013 - val_auc: 0.7925\n",
      "Epoch 4/100\n",
      "588001/588001 [==============================] - 26s 45us/sample - loss: 0.4112 - auc: 0.7658 - val_loss: 0.4006 - val_auc: 0.7915\n",
      "Epoch 5/100\n",
      "588001/588001 [==============================] - 26s 44us/sample - loss: 0.4098 - auc: 0.7680 - val_loss: 0.4001 - val_auc: 0.7917\n",
      "Epoch 6/100\n",
      "588001/588001 [==============================] - 25s 43us/sample - loss: 0.4092 - auc: 0.7690 - val_loss: 0.4002 - val_auc: 0.7927\n",
      "Epoch 7/100\n",
      "588001/588001 [==============================] - 26s 44us/sample - loss: 0.4083 - auc: 0.7701 - val_loss: 0.4014 - val_auc: 0.7914\n",
      "Epoch 8/100\n",
      "586752/588001 [============================>.] - ETA: 0s - loss: 0.4081 - auc: 0.7704Restoring model weights from the end of the best epoch.\n",
      "588001/588001 [==============================] - 26s 44us/sample - loss: 0.4081 - auc: 0.7704 - val_loss: 0.4023 - val_auc: 0.7897\n",
      "Epoch 00008: early stopping\n",
      "0.7820595923221653\n",
      "Train on 588001 samples, validate on 11999 samples\n",
      "Epoch 1/100\n",
      "588001/588001 [==============================] - 33s 56us/sample - loss: 0.4722 - auc: 0.6863 - val_loss: 0.4119 - val_auc: 0.7548\n",
      "Epoch 2/100\n",
      "588001/588001 [==============================] - 26s 44us/sample - loss: 0.4165 - auc: 0.7564 - val_loss: 0.4047 - val_auc: 0.7573\n",
      "Epoch 3/100\n",
      "588001/588001 [==============================] - 26s 44us/sample - loss: 0.4123 - auc: 0.7639 - val_loss: 0.4045 - val_auc: 0.7568\n",
      "Epoch 4/100\n",
      "588001/588001 [==============================] - 26s 44us/sample - loss: 0.4108 - auc: 0.7662 - val_loss: 0.4009 - val_auc: 0.7589\n",
      "Epoch 5/100\n",
      "588001/588001 [==============================] - 26s 44us/sample - loss: 0.4092 - auc: 0.7688 - val_loss: 0.4012 - val_auc: 0.7583\n",
      "Epoch 6/100\n",
      "588001/588001 [==============================] - 26s 44us/sample - loss: 0.4091 - auc: 0.7690 - val_loss: 0.4065 - val_auc: 0.7580\n",
      "Epoch 7/100\n",
      "587776/588001 [============================>.] - ETA: 0s - loss: 0.4084 - auc: 0.7700\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "588001/588001 [==============================] - 26s 44us/sample - loss: 0.4084 - auc: 0.7701 - val_loss: 0.4016 - val_auc: 0.7582\n",
      "Epoch 8/100\n",
      "588001/588001 [==============================] - 26s 44us/sample - loss: 0.4063 - auc: 0.7726 - val_loss: 0.4017 - val_auc: 0.7583\n",
      "Epoch 9/100\n",
      "587776/588001 [============================>.] - ETA: 0s - loss: 0.4062 - auc: 0.7729Restoring model weights from the end of the best epoch.\n",
      "588001/588001 [==============================] - 26s 44us/sample - loss: 0.4062 - auc: 0.7729 - val_loss: 0.4023 - val_auc: 0.7590\n",
      "Epoch 00009: early stopping\n",
      "0.7838673106404961\n",
      "Train on 588001 samples, validate on 11999 samples\n",
      "Epoch 1/100\n",
      "588001/588001 [==============================] - 34s 57us/sample - loss: 0.4690 - auc: 0.6874 - val_loss: 0.4062 - val_auc: 0.7557\n",
      "Epoch 2/100\n",
      "588001/588001 [==============================] - 26s 45us/sample - loss: 0.4159 - auc: 0.7578 - val_loss: 0.4002 - val_auc: 0.7611\n",
      "Epoch 3/100\n",
      "588001/588001 [==============================] - 26s 44us/sample - loss: 0.4122 - auc: 0.7641 - val_loss: 0.4027 - val_auc: 0.7590\n",
      "Epoch 4/100\n",
      "588001/588001 [==============================] - 26s 44us/sample - loss: 0.4105 - auc: 0.7667 - val_loss: 0.4006 - val_auc: 0.7595\n",
      "Epoch 5/100\n",
      "587776/588001 [============================>.] - ETA: 0s - loss: 0.4094 - auc: 0.7686\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "588001/588001 [==============================] - 26s 45us/sample - loss: 0.4093 - auc: 0.7686 - val_loss: 0.4000 - val_auc: 0.7606\n",
      "Epoch 6/100\n",
      "588001/588001 [==============================] - 26s 45us/sample - loss: 0.4075 - auc: 0.7707 - val_loss: 0.4007 - val_auc: 0.7597\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587776/588001 [============================>.] - ETA: 0s - loss: 0.4068 - auc: 0.7719Restoring model weights from the end of the best epoch.\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4068 - auc: 0.7719 - val_loss: 0.3984 - val_auc: 0.7598\n",
      "Epoch 00007: early stopping\n",
      "0.7861108607904647\n",
      "Train on 588001 samples, validate on 11999 samples\n",
      "Epoch 1/100\n",
      "588001/588001 [==============================] - 31s 54us/sample - loss: 0.4682 - auc: 0.6916 - val_loss: 0.4137 - val_auc: 0.7553\n",
      "Epoch 2/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4159 - auc: 0.7574 - val_loss: 0.4043 - val_auc: 0.7593\n",
      "Epoch 3/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4120 - auc: 0.7641 - val_loss: 0.4032 - val_auc: 0.7588\n",
      "Epoch 4/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4106 - auc: 0.7667 - val_loss: 0.4015 - val_auc: 0.7600\n",
      "Epoch 5/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4097 - auc: 0.7682 - val_loss: 0.4006 - val_auc: 0.7588\n",
      "Epoch 6/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4094 - auc: 0.7685 - val_loss: 0.4003 - val_auc: 0.7594\n",
      "Epoch 7/100\n",
      "587776/588001 [============================>.] - ETA: 0s - loss: 0.4081 - auc: 0.7704Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4081 - auc: 0.7703 - val_loss: 0.4050 - val_auc: 0.7595\n",
      "Epoch 00007: early stopping\n",
      "0.7829004870889784\n",
      "Train on 588001 samples, validate on 11999 samples\n",
      "Epoch 1/100\n",
      "588001/588001 [==============================] - 33s 55us/sample - loss: 0.4674 - auc: 0.6903 - val_loss: 0.4083 - val_auc: 0.7817\n",
      "Epoch 2/100\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4160 - auc: 0.7574 - val_loss: 0.4034 - val_auc: 0.7858\n",
      "Epoch 3/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4128 - auc: 0.7630 - val_loss: 0.4000 - val_auc: 0.7861\n",
      "Epoch 4/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4108 - auc: 0.7663 - val_loss: 0.3975 - val_auc: 0.7880\n",
      "Epoch 5/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4096 - auc: 0.7683 - val_loss: 0.3978 - val_auc: 0.7874\n",
      "Epoch 6/100\n",
      "588001/588001 [==============================] - 24s 42us/sample - loss: 0.4088 - auc: 0.7692 - val_loss: 0.3993 - val_auc: 0.7875\n",
      "Epoch 7/100\n",
      "586752/588001 [============================>.] - ETA: 0s - loss: 0.4084 - auc: 0.7700\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "588001/588001 [==============================] - 26s 44us/sample - loss: 0.4084 - auc: 0.7701 - val_loss: 0.3966 - val_auc: 0.7877\n",
      "Epoch 8/100\n",
      "588001/588001 [==============================] - 26s 44us/sample - loss: 0.4068 - auc: 0.7721 - val_loss: 0.3979 - val_auc: 0.7870\n",
      "Epoch 9/100\n",
      "587776/588001 [============================>.] - ETA: 0s - loss: 0.4063 - auc: 0.7726Restoring model weights from the end of the best epoch.\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4063 - auc: 0.7726 - val_loss: 0.3984 - val_auc: 0.7870\n",
      "Epoch 00009: early stopping\n",
      "0.7871770213133499\n",
      "Train on 588001 samples, validate on 11999 samples\n",
      "Epoch 1/100\n",
      "588001/588001 [==============================] - 32s 55us/sample - loss: 0.4699 - auc: 0.6866 - val_loss: 0.4062 - val_auc: 0.7879\n",
      "Epoch 2/100\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4158 - auc: 0.7573 - val_loss: 0.3995 - val_auc: 0.7909\n",
      "Epoch 3/100\n",
      "588001/588001 [==============================] - 24s 42us/sample - loss: 0.4120 - auc: 0.7644 - val_loss: 0.3942 - val_auc: 0.7928\n",
      "Epoch 4/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4106 - auc: 0.7668 - val_loss: 0.3977 - val_auc: 0.7944\n",
      "Epoch 5/100\n",
      "588001/588001 [==============================] - 24s 40us/sample - loss: 0.4101 - auc: 0.7674 - val_loss: 0.3954 - val_auc: 0.7942\n",
      "Epoch 6/100\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4089 - auc: 0.7693 - val_loss: 0.3943 - val_auc: 0.7942\n",
      "Epoch 7/100\n",
      "587776/588001 [============================>.] - ETA: 0s - loss: 0.4086 - auc: 0.7700\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4086 - auc: 0.7700 - val_loss: 0.3936 - val_auc: 0.7932\n",
      "Epoch 8/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4066 - auc: 0.7723 - val_loss: 0.3968 - val_auc: 0.7931\n",
      "Epoch 9/100\n",
      "586752/588001 [============================>.] - ETA: 0s - loss: 0.4063 - auc: 0.7726Restoring model weights from the end of the best epoch.\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4063 - auc: 0.7726 - val_loss: 0.3951 - val_auc: 0.7931\n",
      "Epoch 00009: early stopping\n",
      "0.7937915123314341\n",
      "Train on 588001 samples, validate on 11999 samples\n",
      "Epoch 1/100\n",
      "588001/588001 [==============================] - 32s 55us/sample - loss: 0.4685 - auc: 0.6914 - val_loss: 0.4029 - val_auc: 0.7822\n",
      "Epoch 2/100\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4160 - auc: 0.7572 - val_loss: 0.3971 - val_auc: 0.7857\n",
      "Epoch 3/100\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4128 - auc: 0.7629 - val_loss: 0.4035 - val_auc: 0.7878\n",
      "Epoch 4/100\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4111 - auc: 0.7660 - val_loss: 0.3984 - val_auc: 0.7871\n",
      "Epoch 5/100\n",
      "588001/588001 [==============================] - 25s 43us/sample - loss: 0.4097 - auc: 0.7680 - val_loss: 0.3966 - val_auc: 0.7887\n",
      "Epoch 6/100\n",
      "588001/588001 [==============================] - 24s 42us/sample - loss: 0.4091 - auc: 0.7690 - val_loss: 0.4006 - val_auc: 0.7878\n",
      "Epoch 7/100\n",
      "588001/588001 [==============================] - 24s 42us/sample - loss: 0.4085 - auc: 0.7699 - val_loss: 0.3995 - val_auc: 0.7880\n",
      "Epoch 8/100\n",
      "587776/588001 [============================>.] - ETA: 0s - loss: 0.4080 - auc: 0.7704Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4080 - auc: 0.7705 - val_loss: 0.3999 - val_auc: 0.7883\n",
      "Epoch 00008: early stopping\n",
      "0.7880372721812016\n",
      "Train on 588001 samples, validate on 11999 samples\n",
      "Epoch 1/100\n",
      "588001/588001 [==============================] - 31s 53us/sample - loss: 0.4706 - auc: 0.6895 - val_loss: 0.4059 - val_auc: 0.7772\n",
      "Epoch 2/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4164 - auc: 0.7565 - val_loss: 0.4054 - val_auc: 0.7804\n",
      "Epoch 3/100\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4123 - auc: 0.7635 - val_loss: 0.4061 - val_auc: 0.7805\n",
      "Epoch 4/100\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4107 - auc: 0.7668 - val_loss: 0.4021 - val_auc: 0.7808\n",
      "Epoch 5/100\n",
      "588001/588001 [==============================] - 25s 43us/sample - loss: 0.4098 - auc: 0.7680 - val_loss: 0.4012 - val_auc: 0.7806\n",
      "Epoch 6/100\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4094 - auc: 0.7687 - val_loss: 0.4020 - val_auc: 0.7808\n",
      "Epoch 7/100\n",
      "587776/588001 [============================>.] - ETA: 0s - loss: 0.4082 - auc: 0.7705Restoring model weights from the end of the best epoch.\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4082 - auc: 0.7706 - val_loss: 0.4012 - val_auc: 0.7812\n",
      "Epoch 00007: early stopping\n",
      "0.7797445752472536\n",
      "Train on 588001 samples, validate on 11999 samples\n",
      "Epoch 1/100\n",
      "588001/588001 [==============================] - 33s 56us/sample - loss: 0.4687 - auc: 0.6895 - val_loss: 0.4096 - val_auc: 0.7888\n",
      "Epoch 2/100\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4164 - auc: 0.7568 - val_loss: 0.4005 - val_auc: 0.7905\n",
      "Epoch 3/100\n",
      "588001/588001 [==============================] - 24s 42us/sample - loss: 0.4123 - auc: 0.7638 - val_loss: 0.3973 - val_auc: 0.7899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "588001/588001 [==============================] - 24s 40us/sample - loss: 0.4110 - auc: 0.7660 - val_loss: 0.3987 - val_auc: 0.7894\n",
      "Epoch 5/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4094 - auc: 0.7683 - val_loss: 0.3961 - val_auc: 0.7914\n",
      "Epoch 6/100\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4093 - auc: 0.7684 - val_loss: 0.3964 - val_auc: 0.7904\n",
      "Epoch 7/100\n",
      "587776/588001 [============================>.] - ETA: 0s - loss: 0.4083 - auc: 0.7700Restoring model weights from the end of the best epoch.\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4083 - auc: 0.7701 - val_loss: 0.3972 - val_auc: 0.7898\n",
      "Epoch 00007: early stopping\n",
      "0.7892555424414929\n",
      "Train on 588001 samples, validate on 11999 samples\n",
      "Epoch 1/100\n",
      "588001/588001 [==============================] - 32s 55us/sample - loss: 0.4677 - auc: 0.6891 - val_loss: 0.4096 - val_auc: 0.7763\n",
      "Epoch 2/100\n",
      "588001/588001 [==============================] - 24s 40us/sample - loss: 0.4161 - auc: 0.7571 - val_loss: 0.4040 - val_auc: 0.7825\n",
      "Epoch 3/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4124 - auc: 0.7635 - val_loss: 0.4030 - val_auc: 0.7838\n",
      "Epoch 4/100\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4106 - auc: 0.7666 - val_loss: 0.4075 - val_auc: 0.7829\n",
      "Epoch 5/100\n",
      "588001/588001 [==============================] - 24s 42us/sample - loss: 0.4096 - auc: 0.7685 - val_loss: 0.4000 - val_auc: 0.7836\n",
      "Epoch 6/100\n",
      "587776/588001 [============================>.] - ETA: 0s - loss: 0.4090 - auc: 0.7688\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4090 - auc: 0.7688 - val_loss: 0.4007 - val_auc: 0.7827\n",
      "Epoch 7/100\n",
      "588001/588001 [==============================] - 24s 40us/sample - loss: 0.4070 - auc: 0.7718 - val_loss: 0.4010 - val_auc: 0.7825\n",
      "Epoch 8/100\n",
      "586752/588001 [============================>.] - ETA: 0s - loss: 0.4067 - auc: 0.7721Restoring model weights from the end of the best epoch.\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4068 - auc: 0.7721 - val_loss: 0.4036 - val_auc: 0.7822\n",
      "Epoch 00008: early stopping\n",
      "0.7833258191488265\n",
      "Train on 588001 samples, validate on 11999 samples\n",
      "Epoch 1/100\n",
      "588001/588001 [==============================] - 31s 54us/sample - loss: 0.4682 - auc: 0.6915 - val_loss: 0.4065 - val_auc: 0.7785\n",
      "Epoch 2/100\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4159 - auc: 0.7572 - val_loss: 0.4032 - val_auc: 0.7830\n",
      "Epoch 3/100\n",
      "588001/588001 [==============================] - 24s 42us/sample - loss: 0.4124 - auc: 0.7638 - val_loss: 0.4014 - val_auc: 0.7853\n",
      "Epoch 4/100\n",
      "588001/588001 [==============================] - 24s 42us/sample - loss: 0.4110 - auc: 0.7658 - val_loss: 0.4029 - val_auc: 0.7862\n",
      "Epoch 5/100\n",
      "588001/588001 [==============================] - 24s 42us/sample - loss: 0.4099 - auc: 0.7677 - val_loss: 0.3992 - val_auc: 0.7863\n",
      "Epoch 6/100\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4088 - auc: 0.7694 - val_loss: 0.4018 - val_auc: 0.7866\n",
      "Epoch 7/100\n",
      "588001/588001 [==============================] - 24s 42us/sample - loss: 0.4084 - auc: 0.7700 - val_loss: 0.3993 - val_auc: 0.7858\n",
      "Epoch 8/100\n",
      "588001/588001 [==============================] - 24s 41us/sample - loss: 0.4080 - auc: 0.7705 - val_loss: 0.3996 - val_auc: 0.7857\n",
      "Epoch 9/100\n",
      "586752/588001 [============================>.] - ETA: 0s - loss: 0.4074 - auc: 0.7714\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "588001/588001 [==============================] - 25s 42us/sample - loss: 0.4075 - auc: 0.7713 - val_loss: 0.3998 - val_auc: 0.7855\n",
      "Epoch 10/100\n",
      "587776/588001 [============================>.] - ETA: 0s - loss: 0.4062 - auc: 0.7730Restoring model weights from the end of the best epoch.\n",
      "588001/588001 [==============================] - 24s 42us/sample - loss: 0.4062 - auc: 0.7730 - val_loss: 0.4004 - val_auc: 0.7864\n",
      "Epoch 00010: early stopping\n",
      "0.7856712170851557\n"
     ]
    }
   ],
   "source": [
    "test_data = [test.loc[:, features].values[:, k] for k in range(test.loc[:, features].values.shape[1])]\n",
    "oof_preds = np.zeros((len(train)))\n",
    "test_preds = np.zeros((len(test)))\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=50)\n",
    "for train_idx, test_idx in skf.split(train, train.target.values):\n",
    "    \n",
    "    x_train, x_test = train.iloc[train_idx, :], train.iloc[test_idx, :]\n",
    "    x_train = x_train.reset_index(drop=True)\n",
    "    x_test = x_test.reset_index(drop=True)\n",
    "    \n",
    "    y_train, y_test = x_train.target.values, x_test.target.values\n",
    "    \n",
    "    model = create_model(data, features)\n",
    "    model.compile(loss='binary_crossentropy', optimizers='adam', metrics=[auc])\n",
    "    \n",
    "    x_train = [x_train.loc[:, features].values[:, k] for k in range(x_train.loc[:, features].values.shape[1])]\n",
    "    x_test = [x_test.loc[:, features].values[:, k] for k in range(x_test.loc[:, features].values.shape[1])]\n",
    "    \n",
    "    early_stop = callbacks.EarlyStopping(monitor='val_auc', min_delta=0.001, patience=5, verbose=1, mode='max',\n",
    "                                         baseline=None, restore_best_weights=True)\n",
    "    \n",
    "    reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_auc', factor=0.5, patience=3, min_lr=1e-6, \n",
    "                                           mode='max', verbose=1)\n",
    "    \n",
    "    model.fit(x_train, utils.to_categorical(y_train),\n",
    "             validation_data=(x_test, utils.to_categorical(y_test)),\n",
    "             verbose=1, batch_size=1024, callbacks=[early_stop, reduce_lr], epochs=100)\n",
    "    \n",
    "    valid_fold_preds = model.predict(x_test)[:, 1]\n",
    "    test_fold_preds = model.predict(test_data)[:, 1]\n",
    "    oof_preds[test_idx] = valid_fold_preds.ravel()\n",
    "    test_preds += test_fold_preds.ravel()\n",
    "    print(metrics.roc_auc_score(y_test, valid_fold_preds))\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall AUC=0.7835388190012328\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall AUC={}\".format(metrics.roc_auc_score(train.target.values, oof_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving submission file\n"
     ]
    }
   ],
   "source": [
    "test_preds /= 50\n",
    "test_ids = test.id.values\n",
    "print(\"Saving submission file\")\n",
    "submission = pd.DataFrame.from_dict({\n",
    "    'id': test_ids,\n",
    "    'target': test_preds\n",
    "})\n",
    "submission.to_csv(\"data/submission-22.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.7",
   "language": "python",
   "name": "py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "path = '/home/srgrace/Downloads/IMS_PRO/Recommender_System/ml-latest-small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv(os.path.join(path, 'ratings.csv'))\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv(os.path.join(path, 'movies.csv'))\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>1</th>\n",
       "      <th>50</th>\n",
       "      <th>110</th>\n",
       "      <th>260</th>\n",
       "      <th>296</th>\n",
       "      <th>318</th>\n",
       "      <th>356</th>\n",
       "      <th>480</th>\n",
       "      <th>527</th>\n",
       "      <th>589</th>\n",
       "      <th>593</th>\n",
       "      <th>1196</th>\n",
       "      <th>2571</th>\n",
       "      <th>2858</th>\n",
       "      <th>2959</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>4.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId  1     50    110   260   296   318   356   480   527   589   593   \\\n",
       "userId                                                                      \n",
       "68        2.5   3.0   2.5   5.0   2.0   3.0   3.5   3.5   4.0   3.5   3.5   \n",
       "182       4.0   4.5   3.5   3.5   5.0   4.5   5.0   3.5   4.0   2.0   4.5   \n",
       "249       4.0   4.0   5.0   5.0   4.0   4.5   4.5   4.0   4.5   4.0   4.0   \n",
       "274       4.0   4.0   4.5   3.0   5.0   4.5   4.5   3.5   4.0   4.5   4.0   \n",
       "288       4.5   NaN   5.0   5.0   5.0   5.0   5.0   2.0   5.0   4.0   5.0   \n",
       "307       4.0   4.5   3.5   3.5   4.5   4.5   4.0   3.5   4.5   2.5   4.5   \n",
       "380       5.0   4.0   4.0   5.0   5.0   3.0   5.0   5.0   NaN   5.0   5.0   \n",
       "387       NaN   4.5   3.5   4.5   5.0   3.5   4.0   3.0   NaN   3.5   4.0   \n",
       "414       4.0   5.0   5.0   5.0   5.0   5.0   5.0   4.0   4.0   5.0   4.0   \n",
       "448       5.0   4.0   NaN   5.0   5.0   NaN   3.0   3.0   NaN   3.0   5.0   \n",
       "474       4.0   4.0   3.0   4.0   4.0   5.0   3.0   4.5   5.0   4.0   4.5   \n",
       "599       3.0   3.5   3.5   5.0   5.0   4.0   3.5   4.0   NaN   4.5   3.0   \n",
       "603       4.0   NaN   1.0   4.0   5.0   NaN   3.0   NaN   3.0   NaN   5.0   \n",
       "606       2.5   4.5   3.5   4.5   5.0   3.5   4.0   2.5   5.0   3.5   4.5   \n",
       "610       5.0   4.0   4.5   5.0   5.0   3.0   3.0   5.0   3.5   5.0   4.5   \n",
       "\n",
       "movieId  1196  2571  2858  2959  \n",
       "userId                           \n",
       "68        5.0   4.5   5.0   2.5  \n",
       "182       3.0   5.0   5.0   5.0  \n",
       "249       5.0   5.0   4.5   5.0  \n",
       "274       4.5   4.0   5.0   5.0  \n",
       "288       4.5   3.0   NaN   3.5  \n",
       "307       3.0   3.5   4.0   4.0  \n",
       "380       5.0   4.5   NaN   4.0  \n",
       "387       4.5   4.0   4.5   4.5  \n",
       "414       5.0   5.0   5.0   5.0  \n",
       "448       5.0   2.0   4.0   4.0  \n",
       "474       5.0   4.5   3.5   4.0  \n",
       "599       5.0   5.0   5.0   5.0  \n",
       "603       3.0   5.0   5.0   4.0  \n",
       "606       4.5   5.0   4.5   5.0  \n",
       "610       5.0   5.0   3.5   5.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "g = ratings.groupby('userId')['rating'].count()\n",
    "topUsers = g.sort_values(ascending=False)[:15]\n",
    "\n",
    "g = ratings.groupby('movieId')['rating'].count()\n",
    "topMovies = g.sort_values(ascending=False)[:15]\n",
    "\n",
    "top_r = ratings.join(topUsers, rsuffix='_r', how='inner', on='userId')\n",
    "top_r = top_r.join(topMovies, rsuffix='_r', how='inner', on='movieId')\n",
    "\n",
    "pd.crosstab(top_r.userId, top_r.movieId, top_r.rating, aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fastai collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.collab import CollabDataBunch, collab_learner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>294</td>\n",
       "      <td>1379</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>1375</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>232</td>\n",
       "      <td>30894</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>414</td>\n",
       "      <td>994</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>5816</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = CollabDataBunch.from_df(ratings, valid_pct=0.1)\n",
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural collaborative filtering model\n",
    "\n",
    "user: u -> (u1, u2, ....., un) <br>\n",
    "movie: m -> (m1, m2, ...., mn) <br>\n",
    "rating: r -> u.dot(m) -> u1*m1 + u2*m2 + .....+ un*mn <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = collab_learner(data, n_factors=40, y_range=[0,5.5], wd=.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual model created here contains 2 important enhancements on the simpler version described earlier:\n",
    "\n",
    "First, apart from the vectors for users and movies, it also add bias terms to account for outliers, since some users tend to always rate movies very high or very low, and some movies tend to be universally acclaimed or disliked.\n",
    "\n",
    "\n",
    "user: u -> (u1, u2, ....., un), ub <br>\n",
    "movie: m -> (m1, m2, ...., mn), mb <br>\n",
    "rating: r -> u.dot(m) -> u1*m1 + u2*m2 + .....+ un*mn + ub + mb <br>\n",
    "\n",
    "Second, it applies the Sigmoid activation function to the above output, and scales it so that the result always lies in the given y_range, which is 0 to 5.5 in this case.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "The learner uses the mean squared error loss function to evaluate the predictions of the model, and the Adam optimizer to adjust the parameters (vectors and biases) using gradient descent. Before we train the model, we use the learning rate finder to select a good learning for the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot(skip_end=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon inspection of the graph, we can see that the decrease in loss starts to decrease when the learning rate is around 1e-2. We can choose this as our learning rate, and train for 10 epochs, while annealing the learning rate using the 1-cycle policy, which leads to faster convergence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.520850</td>\n",
       "      <td>0.788877</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.399023</td>\n",
       "      <td>0.731534</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(2, 1e-2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at some predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real\tPred\tDifference\n",
      "5.0\t4.2\t-0.8\n",
      "5.0\t3.5\t-1.5\n",
      "5.0\t4.4\t-0.6\n",
      "2.0\t2.5\t0.5\n",
      "0.5\t3.1\t2.6\n",
      "4.0\t4.4\t0.4\n",
      "4.0\t4.2\t0.2\n",
      "2.5\t3.2\t0.7\n",
      "2.5\t2.9\t0.4\n",
      "4.0\t4.0\t-0.0\n",
      "4.0\t3.9\t-0.1\n",
      "3.0\t2.8\t-0.2\n",
      "3.0\t3.3\t0.3\n",
      "3.5\t3.6\t0.1\n",
      "3.0\t3.5\t0.5\n",
      "4.0\t3.7\t-0.3\n"
     ]
    }
   ],
   "source": [
    "(users, items), ratings = next(iter(data.valid_dl))\n",
    "preds = learn.model(users, items)\n",
    "print('Real\\tPred\\tDifference')\n",
    "for p in list(zip(ratings, preds))[:16]:\n",
    "    print('{}\\t{:.1f}\\t{:.1f}'.format(p[0],p[1],p[1]-p[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning for Movie Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MovieLens Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = '/home/srgrace/Downloads/IMS_PRO/Recommender_System/ml-1m/'\n",
    "\n",
    "# Define file directories\n",
    "MOVIELENS_DIR = path1\n",
    "USER_DATA_FILE = 'users.dat'\n",
    "MOVIE_DATA_FILE = 'movies.dat'\n",
    "RATING_DATA_FILE = 'ratings.dat'\n",
    "\n",
    "# Specify User's Age and Occupation Column\n",
    "AGES = { 1: \"Under 18\", 18: \"18-24\", 25: \"25-34\", 35: \"35-44\", 45: \"45-49\", 50: \"50-55\", 56: \"56+\" }\n",
    "OCCUPATIONS = { 0: \"other or not specified\", 1: \"academic/educator\", 2: \"artist\", 3: \"clerical/admin\",\n",
    "                4: \"college/grad student\", 5: \"customer service\", 6: \"doctor/health care\",\n",
    "                7: \"executive/managerial\", 8: \"farmer\", 9: \"homemaker\", 10: \"K-12 student\", 11: \"lawyer\",\n",
    "                12: \"programmer\", 13: \"retired\", 14: \"sales/marketing\", 15: \"scientist\", 16: \"self-employed\",\n",
    "                17: \"technician/engineer\", 18: \"tradesman/craftsman\", 19: \"unemployed\", 20: \"writer\" }\n",
    "\n",
    "\n",
    "# Define csv files to be saved into\n",
    "USERS_CSV_FILE = 'users.csv'\n",
    "MOVIES_CSV_FILE = 'movies.csv'\n",
    "RATINGS_CSV_FILE = 'ratings.csv'\n",
    "\n",
    "\n",
    "# Read the Ratings File\n",
    "ratings = pd.read_csv(os.path.join(MOVIELENS_DIR, RATING_DATA_FILE), \n",
    "                    sep='::', \n",
    "                    engine='python', \n",
    "                    encoding='latin-1',\n",
    "                    names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
    "\n",
    "# Set max_userid to the maximum user_id in the ratings\n",
    "max_userid = ratings['user_id'].drop_duplicates().max()\n",
    "# Set max_movieid to the maximum movie_id in the ratings\n",
    "max_movieid = ratings['movie_id'].drop_duplicates().max()\n",
    "\n",
    "# Process ratings dataframe for Keras Deep Learning model\n",
    "# Add user_emb_id column whose values == user_id - 1\n",
    "ratings['user_emb_id'] = ratings['user_id'] - 1\n",
    "# Add movie_emb_id column whose values == movie_id - 1\n",
    "ratings['movie_emb_id'] = ratings['movie_id'] - 1\n",
    "\n",
    "\n",
    "# Save into ratings.csv\n",
    "ratings.to_csv(RATINGS_CSV_FILE, \n",
    "               sep='\\t', \n",
    "               header=True, \n",
    "               encoding='latin-1', \n",
    "               columns=['user_id', 'movie_id', 'rating', 'timestamp', 'user_emb_id', 'movie_emb_id'])\n",
    "\n",
    "# Read the Users File\n",
    "users = pd.read_csv(os.path.join(MOVIELENS_DIR, USER_DATA_FILE), \n",
    "                    sep='::', \n",
    "                    engine='python', \n",
    "                    encoding='latin-1',\n",
    "                    names=['user_id', 'gender', 'age', 'occupation', 'zipcode'])\n",
    "users['age_desc'] = users['age'].apply(lambda x: AGES[x])\n",
    "users['occ_desc'] = users['occupation'].apply(lambda x: OCCUPATIONS[x])\n",
    "\n",
    "users.to_csv(USERS_CSV_FILE, \n",
    "             sep='\\t', \n",
    "             header=True, \n",
    "             encoding='latin-1',\n",
    "             columns=['user_id', 'gender', 'age', 'occupation', 'zipcode', 'age_desc', 'occ_desc'])\n",
    "\n",
    "# Read the Movies File\n",
    "movies = pd.read_csv(os.path.join(MOVIELENS_DIR, MOVIE_DATA_FILE), \n",
    "                    sep='::', \n",
    "                    engine='python', \n",
    "                    encoding='latin-1',\n",
    "                    names=['movie_id', 'title', 'genres'])\n",
    "\n",
    "# Save into movies.csv\n",
    "movies.to_csv(MOVIES_CSV_FILE, \n",
    "              sep='\\t', \n",
    "              header=True, \n",
    "              columns=['movie_id', 'title', 'genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reading ratings file\n",
    "ratings = pd.read_csv(os.path.join(path1, 'ratings.csv'), sep='\\t', encoding='latin-1', \n",
    "                      usecols=['user_id', 'movie_id', 'user_emb_id', 'movie_emb_id', 'rating'])\n",
    "\n",
    "max_userid = ratings['user_id'].drop_duplicates().max()\n",
    "max_movieid = ratings['movie_id'].drop_duplicates().max()\n",
    "\n",
    "# Reading ratings file\n",
    "users = pd.read_csv(os.path.join(path1, 'users.csv'), sep='\\t', encoding='latin-1', \n",
    "                    usecols=['user_id', 'gender', 'zipcode', 'age_desc', 'occ_desc'])\n",
    "\n",
    "# Reading ratings file\n",
    "movies = pd.read_csv(os.path.join(path1, 'movies.csv'), sep='\\t', encoding='latin-1', \n",
    "                     usecols=['movie_id', 'title', 'genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users: [5411 5439  367  424 ... 2128  853 4032  785] , shape = (1000209,)\n",
      "Movies: [2682  903 3716 1720 ... 2699 3101 3478 1390] , shape = (1000209,)\n",
      "Ratings: [2 5 4 4 ... 5 3 5 4] , shape = (1000209,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create training set\n",
    "shuffled_ratings = ratings.sample(frac=1., random_state=42)\n",
    "\n",
    "# Shuffling users\n",
    "Users = shuffled_ratings['user_emb_id'].values\n",
    "print('Users:', Users, ', shape =', Users.shape)\n",
    "\n",
    "# Shuffling movies\n",
    "Movies = shuffled_ratings['movie_emb_id'].values\n",
    "print('Movies:', Movies, ', shape =', Movies.shape)\n",
    "\n",
    "# Shuffling ratings\n",
    "Ratings = shuffled_ratings['rating'].values\n",
    "print('Ratings:', Ratings, ', shape =', Ratings.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning Model\n",
    "The idea of using deep learning is similar to that of Model-Based Matrix Factorization. In matrix factorizaion, we decompose our original sparse matrix into product of 2 low rank orthogonal matrices. For deep learning implementation, we dont need them to be orthogonal, we want our model to learn the values of embedding matrix itself. The user latent features and movie latent features are looked up from the embedding matrices for specific movie-user combination. These are the input values for further linear and non-linear layers. We can pass this input to multiple relu, linear or sigmoid layers and learn the corresponding weights by any optimization algorithm (Adam, SGD, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple implementation of matrix factorization for collaborative filtering expressed as a Keras Sequential model\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from keras.layers import Embedding, Reshape, Dot\n",
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "class CFModel(Sequential):\n",
    "\n",
    "    # The constructor for the class\n",
    "    def __init__(self, n_users, m_items, k_factors, **kwargs):\n",
    "        # P is the embedding layer that creates an User by latent factors matrix.\n",
    "        # If the intput is a user_id, P returns the latent factor vector for that user.\n",
    "        models = []\n",
    "        P = Sequential()\n",
    "        P.add(Embedding(n_users, k_factors, input_length=1))\n",
    "        P.add(Reshape((k_factors,)))\n",
    "        models.append(P)\n",
    "\n",
    "        # Q is the embedding layer that creates a Movie by latent factors matrix.\n",
    "        # If the input is a movie_id, Q returns the latent factor vector for that movie.\n",
    "        Q = Sequential()\n",
    "        Q.add(Embedding(m_items, k_factors, input_length=1))\n",
    "        Q.add(Reshape((k_factors,)))\n",
    "        models.append(Q)\n",
    "\n",
    "        super(CFModel, self).__init__(**kwargs)\n",
    "        \n",
    "        # The Merge layer takes the dot product of user and movie latent factor vectors to return the \n",
    "        # corresponding rating.\n",
    "        # self.add(Dot(axes=1)([P, Q]))\n",
    "        \n",
    "        self.add(Dot(axes=1)(models))\n",
    "\n",
    "    # The rate function to predict user's rating of unrated items\n",
    "    def rate(self, user_id, item_id):\n",
    "        return self.predict([np.array([user_id]), np.array([item_id])])[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the main components:\n",
    "\n",
    "* A left embedding layer that creates a Users by Latent Factors matrix.\n",
    "* A right embedding layer that creates a Movies by Latent Factors matrix.\n",
    "* When the input to these layers are (i) a user id and (ii) a movie id, they'll return the latent factor vectors for the user and the movie, respectively.\n",
    "* A merge layer that takes the dot product of these two latent vectors to return the predicted rating.\n",
    "\n",
    "<img src=\"data/collaborative-filter.png\">\n",
    "<a href=\"http://www.fenris.org/2016/03/07/index-html\">ref: fenris's blog</a>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Keras libraries\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "K_FACTORS = 100 # The number of dimensional embeddings for movies and users\n",
    "TEST_USER = 2000 # A random test user (user_id = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer dot_14 was called with an input that isn't a symbolic tensor. Received type: <class 'keras.engine.sequential.Sequential'>. Full input: [<keras.engine.sequential.Sequential object at 0x7f3166f98910>, <keras.engine.sequential.Sequential object at 0x7f3166daf210>]. All inputs to the layer should be tensors.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/PycharmProjects/generic-venv/py3.7/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m                 \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/generic-venv/py3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    473\u001b[0m         raise ValueError('Unexpectedly found an instance of type `' +\n\u001b[0;32m--> 474\u001b[0;31m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m                          'Expected a symbolic tensor instance.')\n",
      "\u001b[0;31mValueError\u001b[0m: Unexpectedly found an instance of type `<class 'keras.engine.sequential.Sequential'>`. Expected a symbolic tensor instance.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-140-dbaad2ef2ff7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Define model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCFModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_userid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_movieid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK_FACTORS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Compile the model using MSE as the loss function and the Adam learning algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-137-5b26d9f66efb>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n_users, m_items, k_factors, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# self.add(Dot(axes=1)([P, Q]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# The rate function to predict user's rating of unrated items\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/generic-venv/py3.7/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/generic-venv/py3.7/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    283\u001b[0m                                  \u001b[0;34m'Received type: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full input: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. All inputs to the layer '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m                                  'should be tensors.')\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Layer dot_14 was called with an input that isn't a symbolic tensor. Received type: <class 'keras.engine.sequential.Sequential'>. Full input: [<keras.engine.sequential.Sequential object at 0x7f3166f98910>, <keras.engine.sequential.Sequential object at 0x7f3166daf210>]. All inputs to the layer should be tensors."
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = CFModel(max_userid, max_movieid, K_FACTORS)\n",
    "# Compile the model using MSE as the loss function and the Adam learning algorithm\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks monitor the validation loss\n",
    "# Save the model weights each time the validation loss has improved\n",
    "callbacks = [EarlyStopping('val_loss', patience=2), \n",
    "             ModelCheckpoint('weights.h5', save_best_only=True)]\n",
    "\n",
    "# Use 30 epochs, 90% training data, 10% validation data \n",
    "history = model.fit([Users, Movies], Ratings, nb_epoch=30, validation_split=.1, verbose=2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root Mean Square Error\n",
    "During the training process above, I saved the model weights each time the validation loss has improved. Thus, I can use that value to calculate the best validation Root Mean Square Error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the best validation RMSE\n",
    "min_val_loss, idx = min((val, idx) for (idx, val) in enumerate(history.history['val_loss']))\n",
    "print('Minimum RMSE at epoch', '{:d}'.format(idx+1), '=', '{:.4f}'.format(math.sqrt(min_val_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimum RMSE at epoch 17 = 0.8616 <br>\n",
    "\n",
    "\n",
    "The best validation loss is 0.7424 at epoch 17. Taking the square root of that number, I got the RMSE value of 0.8616, which is better than the RMSE from the SVD Model (0.8736)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use the pre-trained model\n",
    "trained_model = CFModel(max_userid, max_movieid, K_FACTORS)\n",
    "# Load weights\n",
    "trained_model.load_weights('weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict the ratings given User ID and Movie ID\n",
    "def predict_rating(user_id, movie_id):\n",
    "    return trained_model.rate(user_id - 1, movie_id - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings = ratings[ratings['user_id'] == TEST_USER][['user_id', 'movie_id', 'rating']]\n",
    "user_ratings['prediction'] = user_ratings.apply(lambda x: predict_rating(TEST_USER, x['movie_id']), axis=1)\n",
    "user_ratings.sort_values(by='rating', \n",
    "                         ascending=False).merge(movies, \n",
    "                                                on='movie_id', \n",
    "                                                how='inner', \n",
    "                                                suffixes=['_u', '_m']).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommend Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = ratings[ratings['movie_id'].isin(user_ratings['movie_id']) == False][['movie_id']].drop_duplicates()\n",
    "recommendations['prediction'] = recommendations.apply(lambda x: predict_rating(TEST_USER, x['movie_id']), axis=1)\n",
    "recommendations.sort_values(by='prediction',\n",
    "                          ascending=False).merge(movies,\n",
    "                                                 on='movie_id',\n",
    "                                                 how='inner',\n",
    "                                                 suffixes=['_u', '_m']).head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.7",
   "language": "python",
   "name": "py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
